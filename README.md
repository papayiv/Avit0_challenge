# Avit0_challenge
Решается задача словесной сегментации. В строке, записанной слитно, расставляются пробелы. Для решения задачи используется нейросеть, обученная на pytorch

Главная идея состоит в использовании трансформерной архитектуры с Attention(с 4-мя головами MultiHeadAttention) на входе, получающим токены предобученного BertTokeniser(специально используется многоязыковая модель Берта, так как в тестовой выборке тексты многих языков: я заметил как минимум три - испанский, русский, английский), и в качестве декодера CRF, который с помощью алгоритма Витерби по переходным вероятностям восстанавливает наиболее правдоподобную последовательность символов. Attention выбран неслучайно, а для того, чтобы оценивать важность сразу всех токенов. У той же LSTM даже несмотря на предохранители в виде вентилей - все равно остается угроза забывания, да и учитывает она токены не все сразу, а последовательно - что тоже минус. 

Ранее рассматривался подход без учителя. Так как тренировочная выборка не была предоставлена, была мотивация попробовать решить задачу без поиска дополнительных данных. Использовались вероятностно-частотные подходы на Unigramm-ах(если одна и та же последовательность символов встречается в тестовом тексте достаточно часто - скорее всего это слово; а если разбить слитные строки на фрагменты по n символов, то можно ещё рассмотреть частоты встречаемости таких лексем в парах, друг за другом), но они не дали никакого сколько-нибудь ощутимого результата(максимальный F1-score 23%). Поэтому в конце было решено прибегнуть к более тяжелым моделям.

В качестве датасета используется Complex Russian Dataset(https://www.kaggle.com/datasets/artalmaz31/complex-russian-dataset). Наиболее полезным среди всех текстовых файлов, что его составляют - оказался articles.txt. Он содержит огромную выборку блогов с ЯЧндекс.Дзена. Он учитывает всевозможную современную лексику и названия бытовых приборов(они чаще всего упоминаются в объявлениях Авито) и просто идеально подходил для обучения.

Обучение проходило на Google Colab на GPU T4 - и заняло ~2.5 часа. Обученная модель даёт F1-Score, равный 83 процента, и является достаточно мощной. При увеличении времени обучения и возможно, расширения тренировочной выборки, модель вполне способна достигнуть и более высоких оценок. Но это лишь почва для будущих экспериментов.
