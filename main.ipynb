{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": [],
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Импорт библиотек"
      ],
      "metadata": {
        "id": "7fBhT6pmZCE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import json\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "nV1mcolbte-h"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Считываем данные: тренировочные и тестовые"
      ],
      "metadata": {
        "id": "UhNfdi3gZKIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = open(\"dataset_1937770_3.txt\", \"r\")\n",
        "data = {'id': [], 'text_no_spaces': []}\n",
        "\n",
        "columns = file1.readline().rstrip().split(',')\n",
        "while True:\n",
        "    line = file1.readline().rstrip()\n",
        "    if not line:\n",
        "        break\n",
        "    line_data = line.split(',')\n",
        "    data['id'].append(int(line_data[0]))\n",
        "    data['text_no_spaces'].append(','.join(line_data[1:]))\n",
        "\n",
        "data = pd.DataFrame.from_dict(data)\n",
        "file1.close()"
      ],
      "metadata": {
        "id": "ek86AttNz2js"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_all_text_files(directory=\".\"):\n",
        "    text_files = ['articles.txt']\n",
        "    #['articles.txt', 'books-A.txt', 'books-B.txt', 'fanfiction.txt', 'jokes.txt', 'poems.txt']\n",
        "    all_text = \"\"\n",
        "\n",
        "    for file_path in tqdm(text_files, desc=\"Загрузка файлов\"):\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "            # Удаляем лишние символы (например, \\n\\n)\n",
        "            content = re.sub(r'\\n+', '\\n', content)\n",
        "            all_text += content + \"\\n\"\n",
        "\n",
        "    return all_text.strip()\n",
        "\n",
        "# Загружаем все файлы\n",
        "large_text = load_all_text_files()\n",
        "\n",
        "print(f\"Загружено {len(large_text):,} символов из всех файлов\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl0gSCmLth2d",
        "outputId": "6ef866f4-b65d-4321-c7bb-a93855224d50"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Загрузка файлов: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загружено 21,798,976 символов из всех файлов\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вспомогательные классы"
      ],
      "metadata": {
        "id": "YSTsW6w4ZQmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module): # позиционное кодирование через синусы и косинусы, чтобы attention обращал внимание также на позицию конкретного элемента\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class CRF(nn.Module):\n",
        "    def __init__(self, num_tags, batch_first=True):\n",
        "        super().__init__()\n",
        "        self.num_tags = num_tags\n",
        "        self.batch_first = batch_first\n",
        "        self.transitions = nn.Parameter(torch.randn(num_tags, num_tags))\n",
        "        self.start_transitions = nn.Parameter(torch.randn(num_tags))\n",
        "        self.end_transitions = nn.Parameter(torch.randn(num_tags))\n",
        "\n",
        "    def forward(self, emissions, tags, mask=None, reduction='mean'):\n",
        "        if mask is None:\n",
        "            mask = torch.ones_like(tags, dtype=torch.bool)\n",
        "        if self.batch_first:\n",
        "            emissions = emissions.transpose(0, 1)\n",
        "            tags = tags.transpose(0, 1)\n",
        "            mask = mask.transpose(0, 1)\n",
        "        numerator = self._compute_score(emissions, tags, mask)\n",
        "        denominator = self._compute_normalizer(emissions, mask)\n",
        "        llh = numerator - denominator\n",
        "        if reduction == 'mean':\n",
        "            return llh.mean()\n",
        "        return llh\n",
        "\n",
        "    def decode(self, emissions, mask=None):\n",
        "        if mask is None:\n",
        "            mask = torch.ones(emissions.shape[:2], dtype=torch.bool, device=emissions.device)\n",
        "        if self.batch_first:\n",
        "            emissions = emissions.transpose(0, 1)\n",
        "            mask = mask.transpose(0, 1)\n",
        "        return self._viterbi_decode(emissions, mask)\n",
        "\n",
        "    def _compute_score(self, emissions, tags, mask):\n",
        "        seq_len, batch_size = tags.shape\n",
        "        score = self.start_transitions[tags[0]]\n",
        "        score += emissions[0, torch.arange(batch_size), tags[0]]\n",
        "        for i in range(1, seq_len):\n",
        "            score += self.transitions[tags[i - 1], tags[i]] * mask[i]\n",
        "            score += emissions[i, torch.arange(batch_size), tags[i]] * mask[i]\n",
        "        seq_ends = mask.long().sum(dim=0) - 1\n",
        "        last_tags = tags[seq_ends, torch.arange(batch_size)]\n",
        "        score += self.end_transitions[last_tags]\n",
        "        return score\n",
        "\n",
        "    def _compute_normalizer(self, emissions, mask):\n",
        "        seq_len, batch_size = emissions.shape[:2]\n",
        "        score = self.start_transitions + emissions[0]\n",
        "        for i in range(1, seq_len):\n",
        "            broadcast_score = score.unsqueeze(2)\n",
        "            broadcast_emissions = emissions[i].unsqueeze(1)\n",
        "            next_score = broadcast_score + self.transitions + broadcast_emissions\n",
        "            next_score = torch.logsumexp(next_score, dim=1)\n",
        "            score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
        "        score += self.end_transitions\n",
        "        return torch.logsumexp(score, dim=1)\n",
        "\n",
        "    def _viterbi_decode(self, emissions, mask):  # алгоритм ДП Витерби, подбирающий наиболее вероятную последовательность токенов при заданных вер.переходах\n",
        "        seq_len, batch_size = emissions.shape[:2]\n",
        "        score = self.start_transitions + emissions[0]\n",
        "        history = []\n",
        "        for i in range(1, seq_len):\n",
        "            broadcast_score = score.unsqueeze(2)\n",
        "            broadcast_emissions = emissions[i].unsqueeze(1)\n",
        "            next_score = broadcast_score + self.transitions + broadcast_emissions\n",
        "            next_score, indices = next_score.max(dim=1)\n",
        "            score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
        "            history.append(indices)\n",
        "        score += self.end_transitions\n",
        "        best_tags_list = []\n",
        "        for idx in range(batch_size):\n",
        "            best_last_tag = score[idx].argmax().item()\n",
        "            best_tags = [best_last_tag]\n",
        "            for hist in reversed(history):\n",
        "                best_last_tag = hist[idx][best_tags[-1]].item()\n",
        "                best_tags.append(best_last_tag)\n",
        "            best_tags.reverse()\n",
        "            best_tags_list.append(best_tags)\n",
        "        return best_tags_list\n",
        "\n",
        "class TransformerCRF(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, num_heads=8, num_layers=4, hidden_dim=256, pad_idx=0, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
        "        self.pos_encoder = PositionalEncoding(embed_dim, dropout)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=hidden_dim,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(embed_dim, 2)\n",
        "        self.crf = CRF(num_tags=2, batch_first=True) # декодирует последовательность\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, tags=None, mask=None):\n",
        "        emb = self.embedding(x)\n",
        "        emb = self.pos_encoder(emb)\n",
        "        transformer_out = self.transformer(emb, src_key_padding_mask=~mask if mask is not None else None)\n",
        "        transformer_out = self.dropout(transformer_out)\n",
        "        emissions = self.fc(transformer_out)\n",
        "        if tags is not None:\n",
        "            return -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
        "        else:\n",
        "            return self.crf.decode(emissions, mask=mask)\n",
        "\n",
        "class BERTGuidedLabeler:\n",
        "    def __init__(self, model_name=\"bert-base-multilingual-cased\"):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(model_name) # используем предобученный токенайзер Bert для разных языков(в тестовой выборке встречаются как минимум русский, английский и испанский)\n",
        "\n",
        "    def generate_labels(self, text_with_spaces: str) -> tuple:\n",
        "        text_no_spaces = text_with_spaces.replace(\" \", \"\")\n",
        "        if not text_no_spaces:\n",
        "            return text_no_spaces, []\n",
        "        tokens = self.tokenizer.tokenize(text_with_spaces)\n",
        "        labels = [0] * len(text_no_spaces)\n",
        "        current_pos = 0\n",
        "        for i, token in enumerate(tokens):\n",
        "            clean_token = token[2:] if token.startswith('##') else token\n",
        "            token_len = len(clean_token)\n",
        "            if i > 0 and not token.startswith('##') and current_pos > 0:\n",
        "                labels[current_pos - 1] = 1\n",
        "            current_pos += token_len\n",
        "            if current_pos > len(labels):\n",
        "                break\n",
        "        return text_no_spaces, labels\n",
        "\n",
        "def build_char_vocab(texts):\n",
        "    chars = set()\n",
        "    for text in texts:\n",
        "        chars.update(text)\n",
        "    chars = sorted(list(chars))\n",
        "    char2id = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "    for i, char in enumerate(chars, start=2):\n",
        "        char2id[char] = i\n",
        "    return char2id\n",
        "\n",
        "def restore_spaces(text: str, positions: list[int]) -> str:\n",
        "    if not positions:\n",
        "        return text\n",
        "    chars = list(text)\n",
        "    result = []\n",
        "    for i, ch in enumerate(chars, start=1):\n",
        "        result.append(ch)\n",
        "        if i in positions:\n",
        "            result.append(\" \")\n",
        "    return \"\".join(result).strip()"
      ],
      "metadata": {
        "id": "dAF8F4uHyz_o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## С помощью регулярки подбираем предложения, подходящие для обучения"
      ],
      "metadata": {
        "id": "TciJDFavZeT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeler = BERTGuidedLabeler()\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "\n",
        "\n",
        "sentences = re.split(r'[.!?]+', large_text)\n",
        "sentences = [s.strip() for s in sentences if len(s.strip()) > 5]\n",
        "\n",
        "print(f\"Найдено {len(sentences)} предложений\")\n",
        "\n",
        "for sentence in sentences:\n",
        "    try:\n",
        "        text_no_spaces, labels = labeler.generate_labels(sentence)\n",
        "        if len(text_no_spaces) > 0 and len(labels) == len(text_no_spaces) and 5 <= len(text_no_spaces) <= 128:\n",
        "            train_texts.append(text_no_spaces)\n",
        "            train_labels.append(labels)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(f\"Сгенерировано {len(train_texts)} обучающих примеров\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182,
          "referenced_widgets": [
            "a7affca7b4284848a41cb72e17163646",
            "d185fc614f8a44e3b9883008da26b4bd",
            "a351cc4412ff4f0e8771c50ea8d5c270",
            "d2a8cffebd254b39b516ddfcc276e113",
            "113effaad6a94a75bb67ae7e6ac4c949",
            "5f486f3802184d6daefea28bbee29267",
            "af994cb9a6164e659fba591ce9691b02",
            "a7ba288d338449ea9ac522570baee8c3",
            "9921b413738449bf9af9607563e5ac94",
            "3d5cf2dae9b84a64929d3c4a2b889246",
            "3f02a95f7a1a4c078a2ac0eaeaf6de18",
            "1dd68b2968154171970829b4e7cd1a0e",
            "8c5d058352b7449fbb0eecc1c34630ea",
            "9180846b84454b70bbd86d87d890e8e8",
            "1ed79cdfc0a94467b123d154a8ba04a1",
            "07ae5a4d28c24459a657524a4857ba33",
            "7e48c79321e94d479dabc7ddc20a3a7f",
            "53632d7746194e2f857e9074c5735b52",
            "f5327d9520ad4f2d8b2f11c99b7766c4",
            "c146d612cd024140b39394bc09ea7335",
            "0f22a2159df94ba8baa263d563065080",
            "da55304920514a19b41153a34866d861",
            "319add2c6a5f4e97bf14ad9ffd718619",
            "28895b1b74754b2ea77cd9579cdd0113",
            "f92802b32ad84dd09f61f9a4faa50f57",
            "1dd08c8979044272bd55b77a95a57061",
            "e3d4413634274b54bfb5b9e5078e2d83",
            "4827ee2930e54839b325346048d2c02c",
            "08df22cdb2cf47649bb179e80d69b2f3",
            "b7f10177746545d98fe146c0d72b14d3",
            "2edeba95b9e64ef0910ce96e540ae31e",
            "991964f198b943fdac5b701824d5e10e",
            "1e1c9f09292340339ae28268e7600c3e",
            "af974b98168140868004f6019807b341",
            "88b6a4c09643441aa3404386ab9c7e82",
            "8b10871aa2494ad3a144d7767e4d7d0b",
            "ed5df538ffe0445d8eb0240293ea8e88",
            "922dec9854bd42b092dd823466ed8009",
            "42fc5bfc362d445985e5c46b794397a2",
            "7b178ac45cfe4b768f205bbe4ee6e6f0",
            "e38ebabf90e04c6c831583cb061ca7d1",
            "77d7deea66e646909480382529d1a57f",
            "ab8d76feeb8b4e07875157a41820fea5",
            "e8bb1bd13e944c93b4112817d0e65808"
          ]
        },
        "id": "6_FpoHyc0FjI",
        "outputId": "da3a57e6-b66a-4da1-eb29-3f765bda02cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7affca7b4284848a41cb72e17163646"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1dd68b2968154171970829b4e7cd1a0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "319add2c6a5f4e97bf14ad9ffd718619"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af974b98168140868004f6019807b341"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Найдено 228262 предложений\n",
            "Сгенерировано 195215 обучающих примеров\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Строим словарь символов"
      ],
      "metadata": {
        "id": "PWOuVP4aZ5BM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char2id = build_char_vocab(train_texts)\n",
        "vocab_size = len(char2id)\n",
        "print(f\"\\nРазмер словаря символов: {vocab_size}\")\n",
        "\n",
        "class CharDataset(Dataset):\n",
        "    def __init__(self, texts, labels, char2id, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.char2id = char2id\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        char_ids = [self.char2id.get(c, self.char2id[\"<UNK>\"]) for c in text[:self.max_len]]\n",
        "        label_ids = label[:self.max_len]\n",
        "\n",
        "        if len(char_ids) < self.max_len:\n",
        "            pad_len = self.max_len - len(char_ids)\n",
        "            char_ids.extend([self.char2id[\"<PAD>\"]] * pad_len)\n",
        "            label_ids.extend([0] * pad_len)\n",
        "\n",
        "        mask = [1 if i < len(text) else 0 for i in range(self.max_len)]\n",
        "\n",
        "        return torch.tensor(char_ids, dtype=torch.long), torch.tensor(label_ids, dtype=torch.long), torch.tensor(mask, dtype=torch.bool)\n",
        "\n",
        "train_dataset = CharDataset(train_texts, train_labels, char2id, max_len=128)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOoWdczo0QZ6",
        "outputId": "1f03acdd-fbdc-4445-9a30-a5c5bea65a65"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Размер словаря символов: 385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучаем модель"
      ],
      "metadata": {
        "id": "kzUNr7HTaApk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Используемое устройство: {device}\")\n",
        "\n",
        "model = TransformerCRF(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=128,\n",
        "    num_heads=8,\n",
        "    num_layers=4,\n",
        "    hidden_dim=256,\n",
        "    pad_idx=0\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "print(\"\\nНачинаем обучение...\")\n",
        "model.train()\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/10\", leave=False):\n",
        "        x, y, mask = [t.to(device) for t in batch]\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(x, tags=y, mask=mask)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # предотвращаем exploding gradients\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    scheduler.step()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "# Сохраняем модель и словарь\n",
        "torch.save(model.state_dict(), \"transformer_crf_model.pt\")\n",
        "with open(\"char2id.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(char2id, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"\\n✅ Модель обучена и сохранена\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu1r-qF00nyl",
        "outputId": "231cf883-e8ee-4a70-b8bf-c1cb41a16473"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используемое устройство: cuda\n",
            "\n",
            "Начинаем обучение...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 16.8999, LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 8.7018, LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 6.8578, LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 5.8384, LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 5.2372, LR: 0.000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 4.1806, LR: 0.000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 3.8927, LR: 0.000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 3.7234, LR: 0.000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 3.6019, LR: 0.000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 3.5068, LR: 0.000250\n",
            "\n",
            "✅ Модель обучена и сохранена\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Если есть предобученные параметры - загружаем их, а не ждем пока закончится обучение модели"
      ],
      "metadata": {
        "id": "P1kTzia2ez1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_class, model_params, model_name=\"transformer_crf_model\", device=\"cpu\"):\n",
        "    # Создаём модель и загружаем веса\n",
        "    model = model_class(**model_params)\n",
        "    state_dict = torch.load(f\"{model_name}.pt\", map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Модель {model_name} успешно загружена\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "HnXTRqw3e5ie"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Используемое устройство: {device}\")\n",
        "\n",
        "model_params = {\n",
        "        'vocab_size':385,\n",
        "    'embed_dim':128,\n",
        "    'num_heads':8,\n",
        "    'num_layers':4,\n",
        "    'hidden_dim':256,\n",
        "    'pad_idx':0\n",
        "}\n",
        "\n",
        "model = load_model(\n",
        "        model_class=TransformerCRF,\n",
        "        model_params=model_params,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cReaDn_Zf94b",
        "outputId": "96a579fe-de61-4b36-96dc-8fd8966710bb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используемое устройство: cpu\n",
            "Модель transformer_crf_model успешно загружена\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerCRF(\n",
              "  (embedding): Embedding(385, 128, padding_idx=0)\n",
              "  (pos_encoder): PositionalEncoding(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (transformer): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-3): 4 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              "  (crf): CRF()\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAttZkdtjAY6",
        "outputId": "0abb3a64-40ee-41d4-fa3c-5b3fe13ea1ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('embedding.weight',\n",
              "              tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "                      [ 0.4355, -0.5873,  1.4706,  ...,  2.1009, -2.0358,  1.0402],\n",
              "                      [-0.1497,  0.1223,  0.1568,  ...,  1.1767, -0.0830,  0.0903],\n",
              "                      ...,\n",
              "                      [-0.1125, -0.6970, -0.7342,  ..., -0.4285, -0.6985, -1.9809],\n",
              "                      [-1.1385, -0.7846, -0.1415,  ..., -0.2188,  1.1844, -0.2718],\n",
              "                      [ 0.3265, -0.2086,  0.8627,  ..., -0.0568,  0.1181,  0.7296]])),\n",
              "             ('pos_encoder.pe',\n",
              "              tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
              "                         0.0000e+00,  1.0000e+00],\n",
              "                       [ 8.4147e-01,  5.4030e-01,  7.6172e-01,  ...,  1.0000e+00,\n",
              "                         1.1548e-04,  1.0000e+00],\n",
              "                       [ 9.0930e-01, -4.1615e-01,  9.8705e-01,  ...,  1.0000e+00,\n",
              "                         2.3096e-04,  1.0000e+00],\n",
              "                       ...,\n",
              "                       [ 9.5625e-01, -2.9254e-01, -9.4916e-01,  ...,  7.8608e-01,\n",
              "                         5.4555e-01,  8.3808e-01],\n",
              "                       [ 2.7050e-01, -9.6272e-01, -8.5463e-01,  ...,  7.8599e-01,\n",
              "                         5.4565e-01,  8.3802e-01],\n",
              "                       [-6.6395e-01, -7.4778e-01, -1.5844e-01,  ...,  7.8591e-01,\n",
              "                         5.4574e-01,  8.3795e-01]]])),\n",
              "             ('transformer.layers.0.self_attn.in_proj_weight',\n",
              "              tensor([[-0.1119,  0.0062,  0.0771,  ...,  0.1072,  0.1087,  0.1104],\n",
              "                      [-0.0296, -0.1756, -0.1216,  ...,  0.0467,  0.0822, -0.0082],\n",
              "                      [ 0.0768, -0.0493,  0.0495,  ...,  0.1083, -0.0578, -0.0026],\n",
              "                      ...,\n",
              "                      [ 0.0112, -0.0314, -0.0085,  ...,  0.0592,  0.0078,  0.0890],\n",
              "                      [ 0.0075, -0.0622,  0.0830,  ...,  0.0460,  0.0423,  0.0157],\n",
              "                      [ 0.0089,  0.0268, -0.0403,  ..., -0.0133,  0.0052, -0.0075]])),\n",
              "             ('transformer.layers.0.self_attn.in_proj_bias',\n",
              "              tensor([-4.7946e-02,  6.7294e-02,  1.2391e-01, -7.2512e-02,  8.3843e-02,\n",
              "                      -3.9785e-02,  9.0098e-03, -3.6296e-02, -6.8450e-02, -2.5674e-01,\n",
              "                       3.2917e-02, -1.3156e-01,  8.7086e-02, -4.4585e-02, -9.8578e-02,\n",
              "                       8.4654e-02,  7.0650e-03, -3.4952e-02,  5.2798e-02,  6.2070e-02,\n",
              "                      -7.5647e-02,  1.1788e-01,  3.5809e-02, -5.0794e-02, -6.0402e-02,\n",
              "                       2.2334e-02, -9.5304e-02, -6.5292e-02,  2.6651e-02,  5.4820e-02,\n",
              "                      -4.3736e-02, -8.2677e-03,  4.7345e-03,  1.8574e-01,  1.8757e-02,\n",
              "                       1.0554e-02, -9.6169e-02,  7.0788e-02, -7.5454e-02,  1.7976e-01,\n",
              "                      -3.9543e-02, -6.2781e-02, -5.6834e-02,  4.0615e-02, -1.5240e-01,\n",
              "                       6.4060e-02,  1.1551e-01,  1.2093e-01, -3.9124e-02,  4.4189e-02,\n",
              "                       7.1263e-02,  1.1319e-02, -1.4595e-01,  2.9496e-02,  5.5305e-03,\n",
              "                      -2.5771e-02,  7.0620e-02, -1.1975e-01,  4.4094e-02,  6.8970e-03,\n",
              "                      -1.9218e-02,  1.7646e-02,  5.9156e-02, -2.2543e-02, -3.9108e-02,\n",
              "                      -7.3179e-02,  4.0502e-02, -1.3854e-02,  5.3690e-03, -4.8670e-02,\n",
              "                       1.4505e-01, -2.0747e-02, -9.6993e-02, -8.9269e-02, -1.3248e-01,\n",
              "                       1.0887e-01, -6.2925e-02,  6.7200e-02, -9.0723e-02,  9.0066e-02,\n",
              "                       2.2115e-01, -2.4722e-01,  2.1483e-01, -4.1433e-01, -8.2597e-02,\n",
              "                       2.6057e-01, -2.9875e-01,  1.1283e-01, -4.0348e-01,  1.8349e-01,\n",
              "                       3.7490e-01, -1.0774e-01,  1.0939e-01,  1.3476e-01, -2.2979e-01,\n",
              "                      -2.1470e-03,  5.7872e-02, -8.2043e-02,  4.8396e-02, -6.5667e-02,\n",
              "                      -7.7446e-02,  3.6549e-02, -2.6075e-02,  5.6397e-02,  3.6728e-02,\n",
              "                      -1.0649e-01, -6.9146e-02, -5.7485e-02,  2.5355e-01,  2.7603e-02,\n",
              "                      -2.5952e-02, -9.4417e-02,  1.4752e-01, -1.4738e-01,  4.3617e-01,\n",
              "                       2.1852e-01,  2.3469e-02,  4.1206e-01,  6.9883e-02, -1.3566e-02,\n",
              "                       1.1624e-01,  2.1104e-01, -8.0004e-02,  1.6456e-01, -4.3983e-02,\n",
              "                      -6.3786e-02, -8.8189e-02, -5.5277e-01, -4.0429e-03,  7.3056e-03,\n",
              "                      -7.6680e-03,  1.5957e-04, -7.8500e-03, -3.0464e-03, -5.3189e-03,\n",
              "                       4.7931e-04,  3.4669e-03, -3.8404e-03,  7.6560e-03, -1.8324e-02,\n",
              "                      -9.4179e-04,  1.6072e-03,  8.1268e-03, -1.2752e-04, -2.1549e-04,\n",
              "                      -3.3254e-03, -8.5311e-03,  1.8426e-03,  9.0932e-03,  7.0257e-03,\n",
              "                      -4.7556e-03,  1.3548e-03, -4.3509e-03,  3.3695e-03, -2.1804e-03,\n",
              "                      -5.0712e-03, -1.4956e-03, -1.1119e-02,  4.5361e-03, -5.0524e-03,\n",
              "                      -1.0274e-03,  1.0777e-02,  6.5445e-03, -1.5038e-03, -1.0029e-03,\n",
              "                       8.4212e-03, -2.6971e-03,  2.3948e-03,  8.0095e-03, -9.0233e-04,\n",
              "                      -1.8091e-02, -6.4946e-03, -6.9430e-03,  2.7950e-03,  1.3141e-03,\n",
              "                      -1.1001e-02, -5.5155e-03, -1.1738e-03, -5.8956e-03,  1.6193e-03,\n",
              "                       6.1840e-03,  5.4886e-03,  5.6439e-03,  5.1005e-04,  7.9308e-03,\n",
              "                       4.1607e-04,  3.7704e-03,  6.6414e-03, -1.2273e-03,  4.0514e-03,\n",
              "                       3.9264e-03, -5.0686e-03,  4.1080e-03,  1.0205e-02, -7.1901e-03,\n",
              "                      -5.9728e-03, -3.8303e-03, -9.8087e-03,  2.9400e-04,  1.1543e-02,\n",
              "                       5.6743e-03,  1.0878e-02,  6.8545e-03,  3.0779e-03, -3.1671e-03,\n",
              "                      -8.9504e-03, -9.4908e-03, -2.0340e-03, -1.0205e-03, -1.5461e-03,\n",
              "                       2.8791e-03,  1.5574e-02, -2.9701e-03, -1.6357e-03, -3.3252e-04,\n",
              "                       1.3428e-03,  4.9761e-03, -9.1190e-03,  1.5375e-03, -1.4953e-02,\n",
              "                       5.7027e-03,  1.0277e-02,  2.1575e-03,  3.8214e-03, -5.0738e-04,\n",
              "                      -9.5485e-04,  2.8309e-03, -9.5767e-03,  3.1710e-03,  3.5595e-03,\n",
              "                       6.4755e-04, -5.9185e-03,  6.3356e-03, -2.1830e-03, -6.5430e-03,\n",
              "                      -1.1118e-02,  3.4625e-02, -7.0896e-03, -4.7565e-03,  3.4255e-03,\n",
              "                       7.4758e-02, -3.7725e-02,  4.3581e-02,  3.2872e-02,  3.3670e-02,\n",
              "                       1.4943e-01,  4.2589e-03, -3.5060e-02, -1.1317e-02,  7.8517e-02,\n",
              "                      -8.8681e-04,  2.0652e-02, -3.6430e-02, -7.9257e-03,  9.1334e-03,\n",
              "                      -1.6296e-01, -9.7395e-03, -5.2644e-03,  1.6795e-02, -5.2942e-03,\n",
              "                      -5.5553e-03, -5.0214e-02,  2.4895e-02,  1.6757e-02,  8.4681e-03,\n",
              "                      -5.9808e-03, -4.2926e-03, -2.1906e-03,  9.5291e-03, -9.6467e-03,\n",
              "                      -3.7454e-02,  7.8612e-03,  3.7010e-02,  3.3339e-02, -4.9280e-02,\n",
              "                       5.0180e-02, -7.4841e-03, -4.6521e-02, -9.6006e-03, -3.5574e-02,\n",
              "                      -1.8454e-02,  1.1757e-04, -7.5067e-02,  8.2838e-03, -1.9101e-02,\n",
              "                      -1.8338e-02, -7.0617e-03, -7.0288e-04, -1.6055e-02,  1.2322e-02,\n",
              "                      -4.8973e-03,  6.8677e-03, -4.9716e-03,  5.6717e-03,  2.6872e-02,\n",
              "                      -6.8889e-03,  4.7822e-03,  6.1076e-05, -1.3362e-02,  2.5718e-02,\n",
              "                      -9.6410e-03, -1.3193e-02,  8.5837e-03,  4.8884e-02,  4.7297e-03,\n",
              "                       4.5466e-03, -2.0405e-02, -1.7144e-02,  2.8800e-02,  2.3117e-02,\n",
              "                      -1.5478e-02, -3.5190e-02,  2.5546e-02, -2.8984e-02, -3.9121e-02,\n",
              "                      -6.1381e-03, -8.5773e-05, -1.8686e-04,  1.7711e-02, -2.1812e-02,\n",
              "                       3.1578e-02, -5.6638e-03,  3.3029e-02, -5.5677e-02,  5.3517e-02,\n",
              "                      -1.7312e-02, -3.0253e-02, -2.9627e-03,  5.6976e-03,  5.1982e-02,\n",
              "                       5.6750e-02, -4.0906e-03,  2.6455e-02,  2.9210e-02, -5.0289e-04,\n",
              "                       1.3115e-04,  1.1054e-02, -2.3767e-02, -2.8870e-02, -4.5335e-03,\n",
              "                      -1.8397e-02, -6.6534e-03, -1.2393e-02, -8.1660e-03,  3.2798e-02,\n",
              "                      -4.7190e-02, -1.9103e-02, -1.1234e-02, -7.0310e-03, -1.5326e-02,\n",
              "                      -2.8979e-02,  3.0059e-03, -6.0514e-04,  1.0046e-02, -1.3872e-02,\n",
              "                       1.7328e-02, -7.1711e-02, -1.9858e-02,  3.4598e-02, -1.5261e-02,\n",
              "                       6.9142e-03,  2.5027e-02, -7.1995e-03, -1.3115e-02,  8.1527e-04,\n",
              "                       9.3941e-03, -5.8371e-03, -8.2627e-03, -1.8606e-01,  3.6266e-02,\n",
              "                      -3.4661e-03,  5.3004e-03,  2.3147e-02, -1.2520e-02, -1.2147e-02,\n",
              "                      -4.0977e-02, -7.5731e-03, -1.8650e-02,  1.4659e-02,  2.9901e-02,\n",
              "                      -3.4321e-03, -1.6865e-02,  2.2870e-02,  4.4716e-03])),\n",
              "             ('transformer.layers.0.self_attn.out_proj.weight',\n",
              "              tensor([[ 0.0013,  0.0028,  0.0085,  ..., -0.0128, -0.0066, -0.0055],\n",
              "                      [ 0.0065,  0.0102,  0.0196,  ..., -0.0193, -0.0070,  0.0085],\n",
              "                      [ 0.0174, -0.0080, -0.0212,  ..., -0.0148,  0.0120, -0.0066],\n",
              "                      ...,\n",
              "                      [-0.0995,  0.0776, -0.0305,  ..., -0.0605,  0.0796,  0.0848],\n",
              "                      [-0.0435,  0.0014,  0.0543,  ..., -0.0062,  0.0386, -0.0302],\n",
              "                      [ 0.1402,  0.0774,  0.0187,  ...,  0.0097, -0.0217, -0.0866]])),\n",
              "             ('transformer.layers.0.self_attn.out_proj.bias',\n",
              "              tensor([ 0.0100, -0.0166,  0.0031,  0.0008,  0.0083, -0.0026,  0.0038, -0.0139,\n",
              "                      -0.0132, -0.0234, -0.0049, -0.0159, -0.0071,  0.0223, -0.0323,  0.0243,\n",
              "                      -0.0141,  0.0116, -0.0431,  0.0290,  0.0021,  0.0161,  0.0859,  0.0464,\n",
              "                       0.0326,  0.0228, -0.0080, -0.0434, -0.0209, -0.0541,  0.0617, -0.0239,\n",
              "                      -0.0365, -0.0817,  0.0352, -0.0574, -0.0361, -0.0220,  0.0280, -0.0291,\n",
              "                      -0.0078, -0.0860, -0.0241, -0.0144, -0.1218, -0.1275, -0.0106, -0.0231,\n",
              "                      -0.0881,  0.0655, -0.1039,  0.0206,  0.1116, -0.0774,  0.0002, -0.1853,\n",
              "                       0.0470, -0.0521,  0.0097, -0.0222,  0.0136,  0.1724, -0.0596, -0.0682,\n",
              "                      -0.0563, -0.1569, -0.0506,  0.0945, -0.0712,  0.0497, -0.0207,  0.1443,\n",
              "                       0.0790, -0.0306, -0.1008,  0.0616, -0.0729, -0.1006, -0.0263, -0.0606,\n",
              "                      -0.0315, -0.0220,  0.0202,  0.0274,  0.0957,  0.0209,  0.0534,  0.0162,\n",
              "                      -0.0274, -0.0245,  0.0375, -0.0034, -0.1484,  0.0938, -0.0500,  0.1337,\n",
              "                      -0.0495,  0.1551,  0.0049, -0.0110, -0.0212,  0.0410,  0.0582,  0.0311,\n",
              "                      -0.0303,  0.1185,  0.0088,  0.0572,  0.0397,  0.1086,  0.0600, -0.0853,\n",
              "                      -0.0063,  0.0428,  0.0734,  0.0248, -0.1213,  0.1415, -0.0150, -0.0637,\n",
              "                       0.1391,  0.0104, -0.0475,  0.0225,  0.0918,  0.0551,  0.0914, -0.0079])),\n",
              "             ('transformer.layers.0.linear1.weight',\n",
              "              tensor([[ 0.0143,  0.0290,  0.0431,  ..., -0.3887,  0.2540,  0.1549],\n",
              "                      [-0.0176,  0.0388, -0.1321,  ..., -0.3751,  0.4887,  0.2162],\n",
              "                      [ 0.0294,  0.0438, -0.0546,  ...,  0.0302,  0.0645, -0.0576],\n",
              "                      ...,\n",
              "                      [-0.0419,  0.0334, -0.0271,  ...,  0.1657, -0.2433,  0.4196],\n",
              "                      [ 0.0204,  0.0012,  0.0107,  ..., -0.1187,  0.2361,  0.1330],\n",
              "                      [ 0.0060, -0.0122, -0.0173,  ..., -0.0668, -0.1168, -0.1207]])),\n",
              "             ('transformer.layers.0.linear1.bias',\n",
              "              tensor([-0.2090, -0.4045, -0.2203, -0.3106, -0.2055, -0.3420, -0.2790, -0.1767,\n",
              "                      -0.1575, -0.1572,  0.0099, -0.2468, -0.1178, -0.3196, -0.2787, -0.3351,\n",
              "                      -0.2884, -0.1655, -0.4531, -0.2093, -0.2655, -0.1940, -0.3383, -0.3039,\n",
              "                      -0.3076, -0.3622, -0.2359, -0.3789, -0.2253, -0.0538, -0.3078, -0.3291,\n",
              "                      -0.1094, -0.2707, -0.3688, -0.4340, -0.1447, -0.4404, -0.0388, -0.2323,\n",
              "                      -0.2393, -0.3534, -0.2673, -0.3455, -0.2396, -0.2013, -0.2821, -0.1143,\n",
              "                      -0.3629, -0.2093, -0.2216, -0.2496, -0.3237, -0.3488, -0.1294, -0.2551,\n",
              "                      -0.3982, -0.2953, -0.1573, -0.3496, -0.0658, -0.2835, -0.1203, -0.0790,\n",
              "                      -0.3017, -0.4282, -0.3135, -0.3825, -0.1504, -0.1843, -0.1623, -0.2957,\n",
              "                      -0.2706, -0.2809, -0.3541, -0.2539, -0.2670, -0.3631, -0.3044, -0.1061,\n",
              "                      -0.3623, -0.2578, -0.1817, -0.2742, -0.3147, -0.3112, -0.3568, -0.0930,\n",
              "                      -0.0803, -0.2800, -0.1354, -0.2365, -0.2727, -0.1524, -0.3021, -0.1768,\n",
              "                      -0.1849, -0.1949, -0.2576, -0.1366, -0.4419, -0.2630, -0.1563, -0.1784,\n",
              "                      -0.3610, -0.1854, -0.3393, -0.3497, -0.1836, -0.1030, -0.4630, -0.2608,\n",
              "                      -0.1550, -0.2238, -0.2774, -0.2954, -0.0066, -0.2378, -0.1632, -0.2135,\n",
              "                      -0.0780, -0.3158, -0.0052, -0.2424, -0.1196, -0.1273, -0.3233, -0.2394,\n",
              "                      -0.3572, -0.3036, -0.1224, -0.2609, -0.3509, -0.1904, -0.2606, -0.4000,\n",
              "                      -0.2198, -0.1040, -0.3541, -0.1135, -0.4160, -0.2164, -0.3341, -0.2400,\n",
              "                      -0.2660, -0.2172, -0.3336, -0.3828, -0.2392, -0.1308, -0.2812, -0.2969,\n",
              "                      -0.1825, -0.4389, -0.2371, -0.0619, -0.2537, -0.2319, -0.2227, -0.1829,\n",
              "                      -0.2651, -0.2291, -0.1746, -0.3223, -0.2919, -0.2027, -0.1801, -0.2308,\n",
              "                      -0.3176, -0.1811, -0.1256, -0.3477, -0.2425, -0.2431, -0.2154, -0.3916,\n",
              "                      -0.2816, -0.2522, -0.2465, -0.2822, -0.2632, -0.3680, -0.3946, -0.1200,\n",
              "                      -0.2903, -0.1511, -0.3443, -0.1363, -0.2112, -0.3113, -0.3057, -0.3531,\n",
              "                      -0.2229, -0.2198, -0.3618, -0.2303, -0.1031, -0.2447, -0.0012, -0.0683,\n",
              "                      -0.3181, -0.2709, -0.3746, -0.1979, -0.2498, -0.2325, -0.1791, -0.1736,\n",
              "                      -0.1378, -0.1640, -0.1674, -0.1270, -0.2710, -0.1335, -0.2900, -0.1002,\n",
              "                      -0.2443, -0.1557, -0.0967, -0.3277, -0.1006, -0.3230, -0.1584, -0.1333,\n",
              "                      -0.2121, -0.3026, -0.2215, -0.1404, -0.1893, -0.3247, -0.2854, -0.3101,\n",
              "                      -0.2151, -0.3269, -0.0566, -0.3436, -0.1509, -0.3757, -0.3048, -0.2668,\n",
              "                      -0.4068, -0.1676, -0.2649, -0.3177, -0.3484, -0.1196, -0.2229, -0.2548,\n",
              "                      -0.2478, -0.3365, -0.3466, -0.2362, -0.3335, -0.0155, -0.1782, -0.0460])),\n",
              "             ('transformer.layers.0.linear2.weight',\n",
              "              tensor([[-0.0478, -0.1894, -0.2311,  ...,  0.0154,  0.0269, -0.0582],\n",
              "                      [-0.0329,  0.1628, -0.3907,  ..., -0.0236, -0.0283, -0.0414],\n",
              "                      [ 0.0479,  0.1717, -0.1325,  ...,  0.0398, -0.0645, -0.0812],\n",
              "                      ...,\n",
              "                      [ 0.0958, -0.3660, -0.1165,  ..., -0.1739,  0.0788,  0.2917],\n",
              "                      [-0.0132,  0.5065, -0.0698,  ..., -0.1308,  0.0785, -0.0775],\n",
              "                      [ 0.1007,  0.1393,  0.0709,  ..., -0.0157,  0.0854, -0.0909]])),\n",
              "             ('transformer.layers.0.linear2.bias',\n",
              "              tensor([ 0.0734, -0.0664,  0.0201,  0.0804, -0.0416,  0.1316, -0.0751,  0.1013,\n",
              "                      -0.0410,  0.0805, -0.2036,  0.1028, -0.0046,  0.1735,  0.0112,  0.1520,\n",
              "                      -0.1183, -0.0556, -0.0372,  0.0490, -0.0050, -0.0288, -0.0857,  0.0784,\n",
              "                       0.0660,  0.0007, -0.1431,  0.0326, -0.1225,  0.0162, -0.1205,  0.0574,\n",
              "                      -0.0573, -0.0734,  0.1865, -0.0134, -0.0533,  0.0225, -0.0968, -0.0985,\n",
              "                       0.1103,  0.0264,  0.1796,  0.1127, -0.0619,  0.0161, -0.0931, -0.1725,\n",
              "                      -0.2520,  0.0087,  0.0178, -0.0629, -0.0621,  0.1161, -0.0777, -0.1186,\n",
              "                       0.0591, -0.1181,  0.0044, -0.0272,  0.0727,  0.0264, -0.0084,  0.0607,\n",
              "                      -0.0581, -0.1697, -0.0069, -0.0318,  0.0197, -0.0991,  0.1312,  0.0132,\n",
              "                      -0.1423,  0.0038, -0.2241,  0.0506, -0.1007,  0.0866, -0.0943, -0.2206,\n",
              "                      -0.0796, -0.0602, -0.0381,  0.3394,  0.0242, -0.0168, -0.0032,  0.3020,\n",
              "                      -0.0380, -0.0787, -0.0422,  0.0603, -0.1221,  0.1966, -0.0382,  0.1420,\n",
              "                       0.0494, -0.0269,  0.0211, -0.0202,  0.1932,  0.0907, -0.0101, -0.0773,\n",
              "                       0.0009, -0.1198,  0.1513,  0.0711, -0.3634,  0.0967,  0.1792,  0.1661,\n",
              "                      -0.0560,  0.1829, -0.0164,  0.1724,  0.1009,  0.2045,  0.1991, -0.0592,\n",
              "                      -0.1581, -0.2111,  0.0127, -0.0181,  0.0363, -0.0188, -0.0389, -0.1800])),\n",
              "             ('transformer.layers.0.norm1.weight',\n",
              "              tensor([3.8692, 3.9878, 1.8867, 2.0939, 2.9482, 2.9693, 1.3379, 1.2868, 1.0685,\n",
              "                      1.0763, 0.8027, 0.8340, 2.4351, 2.2209, 0.6632, 0.7249, 0.6689, 0.5148,\n",
              "                      0.7458, 0.8975, 1.1686, 1.1763, 0.5515, 0.6464, 0.5086, 0.5303, 0.4895,\n",
              "                      0.4389, 0.5006, 0.6167, 0.7685, 0.7402, 0.7595, 0.6429, 0.6519, 0.6697,\n",
              "                      0.5063, 0.7847, 0.5815, 0.6803, 0.6091, 0.6740, 0.6736, 0.6915, 0.7411,\n",
              "                      0.6329, 0.6202, 0.6542, 0.5311, 0.5969, 0.7082, 0.7085, 0.5287, 0.6870,\n",
              "                      0.5903, 0.5623, 0.4501, 0.4827, 0.6982, 0.5684, 0.5491, 0.4861, 0.5499,\n",
              "                      0.4811, 0.6734, 0.3970, 0.5923, 0.3415, 0.5700, 0.2847, 0.7816, 0.5334,\n",
              "                      0.7775, 0.2432, 0.6051, 0.3341, 0.6391, 0.5881, 0.6714, 0.3095, 0.7074,\n",
              "                      0.4370, 0.6316, 0.3634, 0.7169, 0.4663, 0.7547, 0.4590, 0.6153, 0.6410,\n",
              "                      0.5385, 0.5170, 0.6271, 0.2620, 0.6292, 0.3824, 0.5782, 0.2527, 0.5753,\n",
              "                      0.3736, 0.4454, 0.5536, 0.5767, 0.4416, 0.6376, 0.4524, 0.6309, 0.4176,\n",
              "                      0.4891, 0.3650, 0.5593, 0.2982, 0.5490, 0.2530, 0.6021, 0.5989, 0.6293,\n",
              "                      0.2829, 0.4896, 0.4744, 0.5988, 0.2889, 0.5869, 0.3876, 0.6840, 0.3306,\n",
              "                      0.5113, 0.3687])),\n",
              "             ('transformer.layers.0.norm1.bias',\n",
              "              tensor([ 0.2642,  0.2640,  0.0480, -0.0779,  0.1933,  0.0015,  0.2561,  0.0144,\n",
              "                      -0.2228, -0.1121, -0.1668, -0.2837,  0.2649, -0.1204, -0.0790, -0.1186,\n",
              "                      -0.0258, -0.3612, -0.2430, -0.0456,  0.1007,  0.1327,  0.1292, -0.1298,\n",
              "                       0.0015, -0.0171,  0.1602, -0.1345, -0.1133, -0.1215,  0.1471, -0.4591,\n",
              "                       0.0708, -0.1827,  0.1343,  0.1014, -0.1754, -0.0377, -0.1814, -0.1934,\n",
              "                       0.0101, -0.1499,  0.0607, -0.0084,  0.0134, -0.1663,  0.1518,  0.2144,\n",
              "                      -0.1571,  0.0159, -0.2245,  0.1634, -0.0794,  0.1197, -0.1386, -0.0058,\n",
              "                       0.1974,  0.0469, -0.2366, -0.1707, -0.1828, -0.0043,  0.1748,  0.2012,\n",
              "                      -0.1147,  0.0726,  0.0846,  0.2234,  0.1214,  0.0522, -0.2002,  0.2308,\n",
              "                       0.0065,  0.0975, -0.4491,  0.1753,  0.0070,  0.2022, -0.2270,  0.0341,\n",
              "                      -0.0830, -0.0412,  0.0470,  0.0443,  0.0717, -0.0395, -0.1768, -0.1308,\n",
              "                      -0.1508, -0.1118, -0.3665, -0.0671,  0.0012,  0.2407, -0.2402,  0.1182,\n",
              "                      -0.5466,  0.2488, -0.0574,  0.1516, -0.1783,  0.0783, -0.2422,  0.0784,\n",
              "                      -0.1308,  0.0068, -0.0597,  0.2687,  0.1311,  0.3352, -0.0500,  0.3372,\n",
              "                       0.2225,  0.4092, -0.1692, -0.2704, -0.2739,  0.3857, -0.1887, -0.0334,\n",
              "                       0.0092,  0.4309, -0.3242,  0.0867, -0.0044,  0.2440, -0.2074,  0.0334])),\n",
              "             ('transformer.layers.0.norm2.weight',\n",
              "              tensor([0.7413, 0.7420, 0.7506, 0.7287, 0.6352, 0.6593, 0.4584, 0.4845, 0.3639,\n",
              "                      0.4176, 0.3616, 0.4042, 0.8625, 0.8838, 0.3553, 0.4040, 0.3899, 0.6365,\n",
              "                      0.7672, 0.8951, 1.0677, 1.0604, 0.7584, 0.8124, 0.6324, 0.6377, 0.5361,\n",
              "                      0.4589, 0.4639, 0.6239, 0.8007, 0.8261, 0.8607, 0.8268, 0.7920, 0.8608,\n",
              "                      0.8245, 0.8462, 0.7963, 0.8368, 0.8821, 0.7743, 0.6817, 0.7197, 0.9719,\n",
              "                      0.7684, 0.9025, 0.8242, 0.6328, 0.8146, 1.0613, 0.7864, 0.7600, 0.8715,\n",
              "                      0.7466, 0.6691, 0.8951, 0.6858, 0.7270, 0.5012, 0.6537, 0.8334, 0.7424,\n",
              "                      0.9208, 0.8062, 0.6232, 0.9356, 0.4589, 0.8442, 0.3395, 0.8527, 0.7246,\n",
              "                      0.9199, 0.2440, 0.8659, 0.8483, 0.5336, 0.9229, 1.0210, 0.4002, 0.6766,\n",
              "                      0.6488, 0.9008, 0.6959, 0.9490, 0.7121, 0.7602, 0.5886, 0.8375, 0.9875,\n",
              "                      0.8831, 0.9358, 0.9538, 0.8439, 0.7998, 0.9135, 0.5189, 0.2220, 0.9926,\n",
              "                      0.3676, 0.4779, 0.7357, 0.8271, 0.7770, 0.8188, 0.8334, 0.8437, 0.5268,\n",
              "                      0.6117, 0.6301, 0.7567, 0.6361, 0.7023, 0.7625, 0.7175, 0.8570, 0.7044,\n",
              "                      0.2264, 0.5361, 0.7154, 0.7918, 0.3725, 0.8429, 0.6949, 0.7890, 0.3008,\n",
              "                      0.8814, 0.4397])),\n",
              "             ('transformer.layers.0.norm2.bias',\n",
              "              tensor([ 1.0050e-01,  1.4323e-01,  6.8292e-02,  2.2606e-01, -5.5617e-02,\n",
              "                       9.1203e-02, -1.0105e-01,  5.7544e-02,  1.2604e-01,  1.5858e-01,\n",
              "                       1.1219e-01,  1.5439e-01,  8.5251e-03,  1.4722e-01, -5.0295e-02,\n",
              "                       1.6257e-02,  6.4343e-02,  1.5506e-01,  2.8217e-01,  2.2498e-03,\n",
              "                      -9.1813e-04, -7.9682e-02, -1.0423e-01,  1.3236e-01, -2.5752e-02,\n",
              "                       3.9805e-02, -8.0961e-02,  4.8818e-02,  8.0061e-02,  1.6619e-01,\n",
              "                      -3.4964e-02, -3.3426e-02, -2.7109e-02,  1.4236e-01, -1.9504e-01,\n",
              "                       7.2504e-02,  1.9751e-02, -2.6172e-03,  1.7385e-01,  1.2290e-01,\n",
              "                      -1.4152e-01,  8.9352e-02, -7.2404e-02, -6.5600e-02,  4.7729e-02,\n",
              "                       6.6415e-02, -1.1924e-01, -1.7937e-01,  1.8759e-01, -9.4312e-02,\n",
              "                       1.0700e-01, -2.5181e-01,  2.0306e-04, -1.6019e-01, -1.1404e-02,\n",
              "                       1.4849e-02, -2.5759e-01,  4.4778e-02,  1.2642e-01,  1.5577e-01,\n",
              "                       8.5850e-02, -1.6752e-01, -1.2626e-01, -3.1030e-01,  1.5940e-01,\n",
              "                       5.1504e-02, -6.8485e-02, -1.7054e-01, -7.6307e-02, -8.1502e-02,\n",
              "                       9.6528e-02, -2.0622e-01,  3.5076e-03, -5.2892e-02,  5.3968e-01,\n",
              "                      -1.2385e-01, -6.3333e-04, -2.6294e-01,  1.7859e-01,  3.2485e-02,\n",
              "                       2.0700e-01, -5.8963e-02,  1.9480e-02, -3.2750e-01, -2.0026e-01,\n",
              "                      -4.3983e-02,  1.0473e-01, -3.4648e-01,  1.8221e-01,  1.1228e-02,\n",
              "                       1.4584e-01, -1.1380e-01,  1.1913e-03, -3.9699e-01,  2.0249e-01,\n",
              "                      -3.9020e-01, -2.6287e-02, -1.2183e-01,  7.6593e-02, -9.5895e-02,\n",
              "                       1.3656e-02, -1.3916e-01,  2.1620e-01, -9.1048e-02,  4.6012e-02,\n",
              "                      -8.2847e-02, -1.6193e-02, -3.4245e-01,  5.2008e-02, -3.6140e-01,\n",
              "                       3.6626e-02, -3.1323e-01, -1.2688e-01, -4.6473e-01,  1.7879e-01,\n",
              "                       2.0964e-02,  1.4374e-02, -3.0038e-01,  1.1586e-02, -1.9522e-01,\n",
              "                       1.5076e-01,  1.0527e-01,  2.9981e-01, -1.9152e-01, -6.2171e-02,\n",
              "                      -1.5774e-01,  1.6717e-01,  8.7137e-02])),\n",
              "             ('transformer.layers.1.self_attn.in_proj_weight',\n",
              "              tensor([[-2.8608e-02,  2.6084e-02, -6.3129e-02,  ..., -9.7741e-02,\n",
              "                        1.0120e-01,  2.8475e-01],\n",
              "                      [ 5.1296e-02,  4.0130e-02,  1.9599e-02,  ..., -8.4635e-02,\n",
              "                       -3.8640e-02,  2.4364e-02],\n",
              "                      [ 3.0979e-02,  5.7652e-02,  6.2575e-03,  ...,  1.0649e-01,\n",
              "                        8.3090e-02, -4.5020e-02],\n",
              "                      ...,\n",
              "                      [ 5.3490e-02,  1.9493e-03,  1.3232e-02,  ...,  1.2673e-02,\n",
              "                        2.8066e-02,  2.7738e-05],\n",
              "                      [-2.9298e-02,  8.4109e-02,  8.9025e-03,  ..., -5.3317e-02,\n",
              "                       -2.5465e-02, -2.1425e-01],\n",
              "                      [-3.1489e-02,  4.2617e-02,  2.8281e-02,  ..., -3.7113e-02,\n",
              "                       -5.0916e-02, -8.5593e-02]])),\n",
              "             ('transformer.layers.1.self_attn.in_proj_bias',\n",
              "              tensor([ 6.1238e-01,  5.0592e-01, -4.8701e-01,  6.0554e-02, -7.3273e-02,\n",
              "                       4.0673e-01,  1.8388e-01,  2.8991e-02, -2.8979e-01, -7.1985e-01,\n",
              "                      -1.1637e-01,  4.9450e-01,  2.9724e-01, -1.4937e-01, -6.9951e-01,\n",
              "                      -4.9404e-02,  4.0920e-01, -2.8923e-01, -2.0571e-01, -7.2742e-01,\n",
              "                      -6.5520e-01,  2.6831e-03, -1.6020e-01, -3.6820e-01, -5.8653e-02,\n",
              "                       4.7705e-01, -3.2096e-01,  6.1981e-01,  1.2537e-01,  2.0499e-01,\n",
              "                      -2.9276e-01, -1.1171e-01, -3.0685e-02, -1.8732e-01, -2.6007e-01,\n",
              "                       3.1088e-01,  2.7710e-01, -1.4408e-01, -1.1684e-01, -3.8834e-01,\n",
              "                      -1.1155e-01, -6.5499e-01, -8.8401e-02,  8.1735e-01, -1.1073e-01,\n",
              "                      -4.9052e-01, -3.6379e-01, -1.5749e-02, -3.3044e-02,  2.9155e-02,\n",
              "                      -1.8910e-01,  1.0237e-01, -8.4756e-02, -1.6524e-01,  4.6992e-02,\n",
              "                      -2.2179e-01,  2.2453e-02,  3.6633e-02,  1.5023e-01, -8.8029e-02,\n",
              "                       6.4644e-02, -1.3670e-01,  7.7205e-02,  3.5728e-02, -5.5018e-01,\n",
              "                      -7.8740e-01,  2.1696e-01, -4.4139e-02, -9.2744e-02, -5.1654e-01,\n",
              "                      -3.9183e-01,  1.6928e-02, -1.9122e-01,  5.3516e-01,  5.8892e-02,\n",
              "                       7.7164e-02,  2.7632e-01, -4.2016e-01,  3.3777e-01,  3.0129e-02,\n",
              "                       5.8257e-01, -7.0803e-01,  6.9797e-01,  8.0049e-01,  3.9417e-01,\n",
              "                      -1.2644e-01,  2.5070e-01,  3.8922e-01, -2.9927e-01,  5.7746e-02,\n",
              "                      -7.3604e-01, -1.9182e-01, -1.8056e-01,  2.0034e-01,  4.4358e-01,\n",
              "                       6.1686e-01,  9.3770e-01,  8.5009e-02, -1.5635e-01, -3.1068e-01,\n",
              "                      -5.6069e-01, -3.8100e-01, -1.4240e+00,  1.6405e-01,  4.3300e-01,\n",
              "                      -6.2425e-02,  1.4233e-01, -1.8077e-01,  9.3229e-03,  1.4430e-01,\n",
              "                      -4.7767e-01,  5.9299e-01, -1.3809e-01,  3.3801e-01, -2.4201e-01,\n",
              "                      -4.7296e-01,  2.9542e-01,  2.6776e-02,  8.8616e-01,  3.1514e-01,\n",
              "                      -7.1615e-02,  4.0328e-02,  9.1236e-01, -1.0763e+00,  8.1776e-02,\n",
              "                      -6.8747e-01, -3.7533e-01, -1.0816e+00,  2.1556e-01,  1.5268e-01,\n",
              "                      -1.1737e-01,  2.4975e-02, -3.1789e-02,  9.3453e-02,  9.3358e-02,\n",
              "                       1.8917e-02, -1.0517e-01, -1.7993e-01, -6.7140e-02,  1.0239e-01,\n",
              "                       1.3136e-01, -5.3251e-02, -1.8273e-01, -2.5304e-02,  5.0602e-03,\n",
              "                       7.1408e-03, -1.7794e-02, -2.5806e-02, -1.9324e-02, -5.5023e-03,\n",
              "                       9.7843e-03,  7.0859e-03, -2.4064e-02,  2.1649e-02,  1.5105e-02,\n",
              "                       2.1852e-02, -2.0790e-02,  1.2344e-02,  1.6183e-03, -2.1666e-02,\n",
              "                      -1.2590e-02,  3.2671e-02, -3.9778e-03, -1.6893e-02,  3.1303e-02,\n",
              "                      -1.2501e-02, -2.5163e-02, -1.6059e-03, -4.2652e-02, -1.7654e-02,\n",
              "                       2.7776e-02,  2.6691e-03,  5.9652e-03, -2.7373e-02, -1.8832e-03,\n",
              "                      -4.7884e-03,  5.9508e-03,  4.4526e-03,  1.4437e-03,  3.2442e-03,\n",
              "                       4.5538e-03,  1.3062e-03, -1.3837e-03,  1.0354e-02,  1.0331e-02,\n",
              "                       4.8535e-04, -5.2566e-03,  3.9945e-03,  1.0790e-02, -8.5570e-04,\n",
              "                      -1.3056e-02, -1.1338e-02,  1.8982e-02,  1.6300e-02, -8.8302e-04,\n",
              "                      -4.8014e-03,  2.6812e-02, -3.1088e-02,  1.5767e-02, -1.5117e-03,\n",
              "                      -1.0075e-02,  8.5576e-03,  1.2061e-02,  9.9469e-03,  1.0775e-02,\n",
              "                      -2.5367e-02, -9.9812e-03, -1.7007e-03,  3.9206e-02,  5.0452e-02,\n",
              "                      -5.2009e-02, -1.4679e-02, -4.8193e-02, -4.5875e-03, -2.9873e-02,\n",
              "                      -7.0575e-02,  3.0750e-02, -2.2409e-02,  7.4102e-02, -4.9808e-02,\n",
              "                       4.4655e-02, -4.9176e-02, -5.6031e-02,  4.1455e-02, -6.2896e-02,\n",
              "                       1.5599e-02, -1.3394e-02, -6.5774e-02,  1.0225e-02,  1.1955e-02,\n",
              "                       1.2259e-02,  1.6414e-02, -6.8058e-03, -3.5983e-02, -4.6494e-02,\n",
              "                      -5.0224e-02, -2.4515e-02, -2.0955e-02,  7.1669e-02,  3.9148e-02,\n",
              "                       4.1287e-03, -6.8840e-02, -6.1555e-03, -1.1618e-02, -4.8635e-02,\n",
              "                       1.1375e-02, -4.6948e-02,  3.5865e-02, -7.0713e-03,  9.6998e-03,\n",
              "                       2.1957e-02, -2.1305e-02, -5.2308e-03, -2.8029e-02, -4.3886e-03,\n",
              "                       6.2856e-02,  2.8002e-02,  8.2246e-02,  1.2627e-02,  3.8743e-02,\n",
              "                       6.0803e-02, -2.9390e-03,  6.9523e-02, -9.4981e-02, -2.5480e-02,\n",
              "                       2.3737e-02,  1.3315e-02, -2.4745e-01, -2.6938e-01, -1.4973e-02,\n",
              "                       1.4715e-01,  3.5494e-02,  1.6242e-01,  7.8750e-02, -6.4684e-02,\n",
              "                      -7.6864e-02, -5.6127e-02, -6.7779e-02, -2.0482e-01, -9.9808e-03,\n",
              "                      -7.3991e-02, -5.1877e-02, -9.6060e-02,  9.6832e-02, -4.1969e-02,\n",
              "                      -3.5910e-02,  5.9541e-02, -6.5730e-02, -9.1967e-03, -4.6646e-02,\n",
              "                       1.9320e-04, -7.4389e-02,  8.5501e-02,  5.2979e-03, -3.0446e-02,\n",
              "                      -3.4374e-02,  3.8511e-02,  1.5245e-02, -2.2547e-02,  2.8732e-02,\n",
              "                       9.7565e-02, -4.5966e-02, -2.5026e-02,  1.2745e-02,  4.2149e-03,\n",
              "                      -2.1803e-02, -5.5769e-02, -1.7458e-02,  3.4843e-02,  1.0833e-01,\n",
              "                      -6.0765e-02, -8.4464e-02,  1.1569e-02, -3.0078e-02,  8.5515e-02,\n",
              "                       2.8346e-02, -1.6709e-02,  1.9132e-02,  1.1137e-02,  1.0745e-01,\n",
              "                      -3.4509e-02, -7.5179e-02,  6.1554e-02,  2.3716e-02, -5.9090e-03,\n",
              "                       7.7468e-02,  8.7979e-02,  7.3743e-02, -1.5723e-01, -2.4678e-02,\n",
              "                       9.2218e-02,  1.4324e-02, -1.6578e-01,  5.2642e-02,  1.1069e-02,\n",
              "                       2.2156e-02, -7.3716e-02,  1.0225e-01,  2.3579e-02,  2.9948e-02,\n",
              "                       4.4085e-02,  6.2070e-02, -1.0911e-01,  5.3092e-02, -8.1867e-02,\n",
              "                      -1.4120e-01,  3.2001e-02,  4.8443e-02,  1.8703e-01,  9.2234e-02,\n",
              "                       1.0303e-01,  1.5433e-01, -7.2020e-02,  6.2886e-02, -1.3998e-01,\n",
              "                      -4.1648e-02, -1.3842e-02, -8.9567e-04, -8.0073e-02,  1.0166e-02,\n",
              "                       2.1680e-01,  1.3197e-02,  6.6498e-02,  1.4538e-01,  1.7919e-02,\n",
              "                       4.8252e-02, -4.8863e-02, -9.8477e-02, -6.3761e-03,  5.5456e-02,\n",
              "                       1.6825e-01, -1.8592e-02,  1.0417e-01,  9.8001e-02,  6.0778e-02,\n",
              "                      -9.2061e-02, -1.2640e-01, -2.4882e-01, -1.2071e-02, -4.9958e-03,\n",
              "                       8.4638e-02, -9.6318e-02, -4.4493e-02,  1.5709e-02])),\n",
              "             ('transformer.layers.1.self_attn.out_proj.weight',\n",
              "              tensor([[ 0.0180,  0.0194, -0.0177,  ...,  0.0599, -0.1511, -0.1414],\n",
              "                      [ 0.0349,  0.0302, -0.0054,  ...,  0.0350,  0.1685, -0.0343],\n",
              "                      [ 0.2116, -0.0069, -0.2351,  ...,  0.5543, -0.0105, -0.2926],\n",
              "                      ...,\n",
              "                      [ 0.0190, -0.0763,  0.0819,  ..., -0.1067, -0.1492, -0.3964],\n",
              "                      [-0.0646, -0.0297,  0.0485,  ...,  0.0803, -0.0627,  0.1755],\n",
              "                      [ 0.1402, -0.1100, -0.1636,  ...,  0.1426,  0.1111,  0.0101]])),\n",
              "             ('transformer.layers.1.self_attn.out_proj.bias',\n",
              "              tensor([-6.1232e-02, -7.6771e-03,  4.8690e-01,  2.2501e-01, -5.0302e-01,\n",
              "                      -1.4497e-01,  3.3815e-01, -2.2927e-01, -1.1468e-01,  2.0071e-01,\n",
              "                      -4.4889e-01,  7.3020e-02, -8.6238e-03, -8.2223e-03, -2.2516e-01,\n",
              "                      -2.4096e-01,  8.5785e-02,  3.4403e-02,  1.1428e-01,  1.5489e-01,\n",
              "                       6.9655e-03, -8.5461e-02,  1.3828e-01,  3.0959e-02, -8.9966e-03,\n",
              "                       1.2394e-01, -1.0632e-01,  4.0290e-02, -1.3428e-01, -7.8192e-02,\n",
              "                       1.1169e-01, -1.3140e-01, -9.1951e-02,  7.3063e-02,  1.3455e-01,\n",
              "                       3.7630e-02, -1.3871e-01, -1.6729e-01, -6.1801e-02,  1.1353e-01,\n",
              "                       3.8575e-04,  7.5501e-02,  7.5811e-02, -6.4196e-03, -1.6459e-01,\n",
              "                       1.3675e-02,  6.3203e-02, -4.1941e-02, -7.9781e-02, -7.6468e-02,\n",
              "                      -1.0491e-01, -7.9738e-02,  9.0155e-02, -5.3455e-03, -1.2343e-01,\n",
              "                      -1.4307e-01,  1.1848e-01, -2.8634e-01,  3.7071e-02,  1.2756e-01,\n",
              "                       1.5605e-01,  1.0997e-01, -3.3881e-01,  2.5037e-02,  1.7894e-02,\n",
              "                       6.6309e-02,  9.1491e-02,  2.0781e-01, -9.1692e-03,  8.6553e-02,\n",
              "                      -1.5715e-02,  3.5169e-01,  2.3982e-01,  1.0438e-01, -1.5476e-01,\n",
              "                      -7.2441e-02, -6.0305e-02,  5.4249e-02,  5.5872e-02, -5.6634e-02,\n",
              "                       2.0399e-01, -2.2495e-01,  1.2297e-01, -2.3037e-01,  3.4649e-02,\n",
              "                      -3.0226e-01,  6.0951e-02, -1.2607e-01,  1.1132e-01,  4.8544e-03,\n",
              "                       1.5735e-02,  1.6202e-01, -1.9514e-01,  1.2244e-01, -1.4922e-01,\n",
              "                       2.3093e-01, -2.4762e-01,  3.9170e-01, -4.9639e-02, -3.4620e-02,\n",
              "                      -3.3660e-01, -1.2532e-01,  4.1478e-02, -4.4774e-02, -1.5241e-02,\n",
              "                       1.4919e-01,  1.1791e-01, -2.5482e-01,  1.1331e-01,  1.4451e-01,\n",
              "                       1.6326e-02,  2.1784e-01, -8.5474e-02,  1.2148e-01,  7.9517e-02,\n",
              "                       8.7309e-03, -2.3587e-01,  3.4877e-02, -2.2084e-01,  2.8469e-02,\n",
              "                       1.2980e-02,  3.3256e-01, -2.2292e-01, -2.0142e-01,  2.2524e-01,\n",
              "                       2.2729e-01,  7.6176e-02, -1.6581e-01])),\n",
              "             ('transformer.layers.1.linear1.weight',\n",
              "              tensor([[ 0.0222,  0.0204,  0.1470,  ..., -0.0955,  0.1246,  0.0303],\n",
              "                      [ 0.0188, -0.0198, -0.2534,  ..., -0.2214,  0.5309, -0.3309],\n",
              "                      [ 0.0473, -0.0612,  0.3615,  ..., -0.3176,  0.2564, -0.0886],\n",
              "                      ...,\n",
              "                      [ 0.0297, -0.0314,  0.1745,  ..., -0.0457, -0.0898, -0.2618],\n",
              "                      [ 0.0126,  0.0025,  0.0744,  ..., -0.1263,  0.1943, -0.4223],\n",
              "                      [-0.0027, -0.0385, -0.1749,  ...,  0.0463, -0.1362, -0.1562]])),\n",
              "             ('transformer.layers.1.linear1.bias',\n",
              "              tensor([-0.2615, -0.2603, -0.4258, -0.2458, -0.2719, -0.5041, -0.4048, -0.3920,\n",
              "                      -0.2375, -0.2488, -0.1628, -0.2561, -0.3272, -0.3453, -0.2886, -0.3744,\n",
              "                      -0.3526, -0.3600, -0.2364, -0.1849, -0.2107, -0.4233, -0.3015, -0.3232,\n",
              "                      -0.3810, -0.2428, -0.3623, -0.2421, -0.2044, -0.3022, -0.3778, -0.1892,\n",
              "                      -0.3243, -0.2850, -0.2929, -0.3300, -0.4317, -0.4829, -0.1406, -0.1744,\n",
              "                      -0.5118, -0.4043, -0.1960, -0.3415, -0.2033, -0.2022, -0.3228, -0.1860,\n",
              "                      -0.3115, -0.2596, -0.2993, -0.2940, -0.3732, -0.3088, -0.0523, -0.2760,\n",
              "                      -0.2415, -0.3178, -0.4345, -0.1903, -0.2108, -0.2880, -0.1279, -0.3211,\n",
              "                      -0.4619, -0.4345, -0.2278, -0.3066, -0.2610, -0.3788, -0.1447, -0.3046,\n",
              "                      -0.4410, -0.2436, -0.2496, -0.4881, -0.2895, -0.2768, -0.2989, -0.1654,\n",
              "                      -0.2879, -0.3986, -0.3119, -0.2729, -0.2570, -0.1673, -0.3233, -0.1882,\n",
              "                      -0.2216, -0.2625, -0.3507, -0.3805, -0.2366, -0.2538, -0.3820, -0.3639,\n",
              "                      -0.1929, -0.2386, -0.2533, -0.2035, -0.4891, -0.3060, -0.3468, -0.3822,\n",
              "                      -0.3585, -0.3770, -0.2674, -0.4212, -0.2360, -0.3678, -0.5212, -0.0688,\n",
              "                      -0.1433, -0.4171, -0.4991, -0.4373, -0.1427, -0.3226, -0.2278, -0.3633,\n",
              "                      -0.3202, -0.1495, -0.1818, -0.2790, -0.2817, -0.2999, -0.3651, -0.0983,\n",
              "                      -0.3478, -0.2894, -0.1513, -0.3782, -0.1730, -0.2724, -0.2461, -0.3952,\n",
              "                      -0.2797, -0.4735, -0.2164, -0.2743, -0.3562, -0.4224, -0.3170, -0.3600,\n",
              "                      -0.2831, -0.2230, -0.3105, -0.3706, -0.2810, -0.2901, -0.3307, -0.2341,\n",
              "                      -0.3465, -0.4575, -0.2496, -0.3479,  0.0545, -0.2303, -0.2771, -0.3761,\n",
              "                      -0.3046, -0.3492, -0.2533, -0.2188, -0.5259, -0.2406, -0.4070, -0.2607,\n",
              "                      -0.0878, -0.3707, -0.2544, -0.3814, -0.3770, -0.3146, -0.3931, -0.4025,\n",
              "                      -0.1429, -0.1492, -0.3406, -0.2784, -0.3611, -0.4962, -0.3420, -0.2540,\n",
              "                      -0.3177, -0.4394, -0.1976, -0.2260, -0.3855, -0.3635, -0.3074, -0.3387,\n",
              "                      -0.2153, -0.1865, -0.2673, -0.3608, -0.3319, -0.2752, -0.0097, -0.4083,\n",
              "                      -0.3345, -0.2206, -0.3981, -0.2442, -0.2885, -0.3473, -0.2433, -0.0620,\n",
              "                      -0.3518, -0.3673, -0.1521, -0.4263, -0.5974, -0.1810, -0.2646, -0.2134,\n",
              "                      -0.3686, -0.0834, -0.3371, -0.2963, -0.1969, -0.3518, -0.3671, -0.3525,\n",
              "                      -0.3692, -0.3451, -0.3854, -0.3171, -0.4071, -0.4001, -0.2689, -0.2607,\n",
              "                      -0.3412, -0.1980, -0.2770, -0.3341, -0.3908, -0.2437, -0.2332, -0.1809,\n",
              "                      -0.4017, -0.3815, -0.3383, -0.2598, -0.4158, -0.3640, -0.2221, -0.2876,\n",
              "                      -0.2379, -0.3855, -0.4144, -0.3448, -0.3230, -0.2757, -0.3028, -0.1741])),\n",
              "             ('transformer.layers.1.linear2.weight',\n",
              "              tensor([[ 0.0154,  0.0301, -0.0648,  ...,  0.0129, -0.0644, -0.0849],\n",
              "                      [ 0.0171, -0.0323,  0.0055,  ..., -0.0594,  0.0080,  0.1176],\n",
              "                      [-0.2858, -0.1412,  0.0270,  ..., -0.0619, -0.2288,  0.0043],\n",
              "                      ...,\n",
              "                      [ 0.0915,  0.1432,  0.1238,  ...,  0.1026, -0.1544,  0.0636],\n",
              "                      [ 0.2115,  0.1977, -0.0825,  ...,  0.1699, -0.0993, -0.1717],\n",
              "                      [ 0.0298, -0.2186, -0.1144,  ...,  0.1223,  0.2323,  0.0688]])),\n",
              "             ('transformer.layers.1.linear2.bias',\n",
              "              tensor([ 0.0328, -0.0451,  0.1253, -0.0257,  0.0116,  0.1126,  0.1029,  0.0713,\n",
              "                       0.0083, -0.0351,  0.0155,  0.0627,  0.0397,  0.0769, -0.2766, -0.1113,\n",
              "                       0.0615,  0.3659,  0.3084,  0.0385, -0.0948, -0.0337,  0.2344,  0.2323,\n",
              "                      -0.1827,  0.1006,  0.0181,  0.3201,  0.0711,  0.0678,  0.2075,  0.1060,\n",
              "                       0.0024,  0.0526, -0.0552, -0.1104,  0.1202, -0.0938,  0.0391,  0.2396,\n",
              "                       0.0178,  0.2485,  0.0095, -0.1951,  0.1882,  0.0788, -0.1227, -0.0495,\n",
              "                       0.0979, -0.0119,  0.1195, -0.0342, -0.0561, -0.0438, -0.0441, -0.3428,\n",
              "                      -0.1653,  0.3466,  0.0924, -0.0654,  0.1169, -0.3049, -0.3300, -0.0948,\n",
              "                      -0.0782, -0.0937, -0.0178, -0.1961, -0.0338,  0.1252, -0.0117, -0.3162,\n",
              "                       0.1387, -0.0142,  0.1906, -0.1576,  0.0249,  0.0342,  0.2687,  0.0769,\n",
              "                      -0.0842, -0.2811, -0.3003, -0.0849,  0.0465,  0.0719,  0.0294, -0.0489,\n",
              "                      -0.0296,  0.1187,  0.2120, -0.0637,  0.1222, -0.2898,  0.1773, -0.3292,\n",
              "                      -0.0034,  0.2390, -0.0363, -0.0890, -0.0646, -0.2762,  0.2191,  0.0590,\n",
              "                      -0.0261, -0.1001, -0.1280, -0.0040,  0.1046, -0.1820,  0.0844, -0.0873,\n",
              "                      -0.1756, -0.3183,  0.1035, -0.0501,  0.0559,  0.0283,  0.0587, -0.0303,\n",
              "                       0.1480,  0.2656,  0.0754, -0.1182, -0.2699, -0.1434,  0.0798, -0.0720])),\n",
              "             ('transformer.layers.1.norm1.weight',\n",
              "              tensor([0.9216, 0.9487, 0.2790, 0.2236, 0.1849, 0.1520, 0.3735, 0.3122, 0.3552,\n",
              "                      0.3134, 0.4904, 0.6702, 1.7825, 1.8632, 0.6056, 0.6797, 0.6860, 0.9699,\n",
              "                      1.3234, 1.9351, 2.1610, 2.1032, 1.0564, 1.4358, 0.8518, 0.9415, 0.6903,\n",
              "                      0.6380, 0.4817, 0.8981, 1.3729, 1.4150, 1.1631, 1.1199, 1.1619, 1.4555,\n",
              "                      1.1247, 1.5600, 1.0865, 1.1603, 1.2486, 1.1697, 0.9485, 1.0369, 1.3683,\n",
              "                      0.9674, 1.0083, 1.2319, 0.6211, 1.0409, 1.2046, 1.0994, 0.8942, 1.2961,\n",
              "                      0.7946, 0.8255, 0.8347, 0.7912, 0.7857, 0.5828, 0.7861, 0.9009, 0.7898,\n",
              "                      1.0825, 0.9409, 0.6696, 1.2771, 0.5969, 0.8030, 0.4630, 1.0724, 1.0031,\n",
              "                      1.1647, 0.4135, 0.8261, 0.7400, 0.5755, 0.9320, 1.0256, 0.6199, 0.8831,\n",
              "                      0.5764, 0.9602, 0.5485, 1.1387, 0.6410, 0.9437, 0.7200, 0.9087, 1.2417,\n",
              "                      0.9500, 0.9258, 0.9925, 0.5959, 0.6970, 0.8989, 0.7847, 0.4492, 1.1219,\n",
              "                      0.5454, 0.5464, 0.6843, 0.8801, 0.7671, 0.8447, 1.0236, 0.8517, 0.5273,\n",
              "                      0.5966, 0.6476, 0.8450, 0.4882, 0.7122, 0.5920, 0.6433, 0.9798, 0.8965,\n",
              "                      0.4592, 0.5774, 0.9227, 0.9074, 0.5910, 0.7142, 0.6009, 1.1016, 0.4870,\n",
              "                      0.7935, 0.4601])),\n",
              "             ('transformer.layers.1.norm1.bias',\n",
              "              tensor([-0.1883,  0.1422, -0.1754, -0.2764, -0.0423, -0.6076,  0.1889, -0.0982,\n",
              "                      -0.2150,  0.0833, -0.1541, -0.2958,  0.0438, -0.4776,  0.0271, -0.2822,\n",
              "                      -0.1982, -0.3879, -0.3759, -0.3793,  0.0579, -0.2278, -0.0908, -0.5560,\n",
              "                       0.1568, -0.1260,  0.0429, -0.5662,  0.0585, -0.0674, -0.0931, -0.6619,\n",
              "                      -0.1311, -0.0106, -0.1903,  0.6200, -0.1368,  0.0465, -0.1795, -0.1474,\n",
              "                       0.0595, -0.1042, -0.0878, -0.3010,  0.1683, -0.0513,  0.3720,  0.0538,\n",
              "                       0.0640, -0.1360,  0.0699, -0.0524, -0.1011,  0.2871, -0.0469,  0.4654,\n",
              "                       0.0282,  0.3528, -0.3099,  0.0345, -0.2197,  0.0795,  0.3471, -0.0467,\n",
              "                       0.1819,  0.5835,  0.0817,  0.4043,  0.1348,  0.0408, -0.2200,  0.6749,\n",
              "                       0.0251,  0.6087, -0.0525,  0.3388,  0.0396,  0.3489, -0.2920,  0.2749,\n",
              "                       0.2105,  0.2169,  0.2870, -0.0670,  0.0212,  0.2431, -0.2586, -0.9045,\n",
              "                       0.2148,  0.0335, -0.6616,  0.0497, -0.0321,  0.0856, -0.0338,  0.1886,\n",
              "                      -1.0983,  0.0355, -0.2113,  0.1892, -0.5159,  0.4975, -0.4639,  0.3208,\n",
              "                      -0.0959,  0.4353, -0.1335,  0.0308,  0.7231,  0.4585, -0.3284,  0.2903,\n",
              "                       0.2467,  0.3396, -0.2342, -0.1366, -0.3350,  0.0639, -0.8237,  0.1249,\n",
              "                       0.0541,  0.9742, -0.4104,  0.3293, -0.1583,  0.4295, -0.3177,  0.7705])),\n",
              "             ('transformer.layers.1.norm2.weight',\n",
              "              tensor([0.8161, 0.7989, 0.5616, 0.5096, 0.4299, 0.4544, 0.4635, 0.5638, 0.5275,\n",
              "                      0.5862, 0.5892, 0.6070, 0.6148, 0.6043, 0.5881, 0.6107, 0.5929, 0.6179,\n",
              "                      0.6290, 0.5734, 0.6038, 0.6240, 0.6500, 0.5891, 0.7446, 0.6612, 0.5986,\n",
              "                      0.5999, 0.6804, 0.6469, 0.6227, 0.6930, 0.7478, 0.8020, 0.6833, 0.6728,\n",
              "                      0.6273, 0.6913, 0.7175, 0.7669, 0.7108, 0.6048, 0.6263, 0.7153, 0.6823,\n",
              "                      0.7336, 0.7713, 0.6933, 0.5044, 0.7283, 0.8001, 0.6977, 0.6543, 0.7325,\n",
              "                      0.7591, 0.6518, 0.7973, 0.6532, 0.7690, 0.6521, 0.7244, 0.7591, 0.7185,\n",
              "                      0.7236, 0.7449, 0.6720, 0.8157, 0.6761, 0.7034, 0.5637, 0.7226, 0.6780,\n",
              "                      0.7942, 0.5815, 0.6682, 0.7920, 0.5429, 0.8240, 0.7862, 0.6323, 0.7028,\n",
              "                      0.5885, 0.7433, 0.7206, 0.8123, 0.7304, 0.7325, 0.4916, 0.6995, 0.7998,\n",
              "                      0.7146, 0.7428, 0.7317, 0.6589, 0.6691, 0.7510, 0.4583, 0.6139, 0.9057,\n",
              "                      0.5009, 0.6184, 0.7217, 0.6574, 0.7160, 0.7097, 0.7385, 0.7092, 0.7728,\n",
              "                      0.5189, 0.6516, 0.7800, 0.6336, 0.7430, 0.6600, 0.7246, 0.7565, 0.7033,\n",
              "                      0.5182, 0.6278, 0.6809, 0.7210, 0.5059, 0.6386, 0.6651, 0.7757, 0.6292,\n",
              "                      0.7303, 0.6171])),\n",
              "             ('transformer.layers.1.norm2.bias',\n",
              "              tensor([ 1.2777e-01, -1.1112e-01,  1.0047e-01,  1.1374e-01,  3.9538e-02,\n",
              "                       2.6273e-01, -3.4193e-02,  2.7745e-03,  8.4769e-02,  1.9941e-02,\n",
              "                       9.0546e-02,  1.5362e-01, -2.5046e-02,  3.1598e-01, -3.8246e-02,\n",
              "                       1.3622e-01,  1.1306e-01,  2.1600e-01,  1.6144e-01,  1.6795e-01,\n",
              "                      -6.5084e-02,  9.3269e-02,  4.9274e-02,  2.3179e-01, -9.9333e-02,\n",
              "                       6.4026e-02,  1.0908e-02,  1.2187e-01, -2.1891e-02,  5.0525e-03,\n",
              "                       1.2822e-02,  5.5194e-01,  4.0362e-02, -2.9540e-02,  1.3161e-01,\n",
              "                      -3.2454e-01,  3.4713e-02, -1.1609e-01,  1.4053e-01,  1.0530e-01,\n",
              "                      -3.2416e-02,  3.9532e-02, -4.1857e-04,  2.9583e-01, -7.2151e-02,\n",
              "                       5.9799e-03, -2.6785e-01, -1.3986e-01, -6.7040e-02,  1.1966e-01,\n",
              "                       6.0204e-02, -2.6922e-02,  4.9051e-02, -1.7503e-01,  3.4763e-02,\n",
              "                      -2.3545e-01, -5.1338e-02, -2.5882e-01,  2.1204e-01,  2.6873e-02,\n",
              "                       1.7658e-01, -5.6853e-02, -3.1640e-01, -3.2066e-02, -1.8450e-01,\n",
              "                      -3.1519e-01, -1.2153e-01, -2.2250e-01, -8.7301e-02, -1.9486e-02,\n",
              "                       1.5854e-01, -4.1259e-01, -2.9609e-02, -2.7149e-01,  3.7338e-02,\n",
              "                      -3.0163e-01, -4.9957e-02, -3.9756e-01,  2.3943e-01, -1.7335e-01,\n",
              "                      -1.2278e-01, -1.5258e-01, -2.1415e-01,  3.6413e-02,  3.7989e-02,\n",
              "                      -1.4783e-01,  2.0248e-01,  1.0971e-01, -1.4706e-01, -3.7550e-02,\n",
              "                       4.3413e-01, -1.1127e-02,  4.9834e-02, -5.8986e-02,  3.4022e-02,\n",
              "                      -1.7018e-01,  4.5041e-01, -2.9696e-02,  8.2755e-02, -1.3539e-01,\n",
              "                       2.7697e-01, -3.1565e-01,  3.0036e-01, -1.8241e-01,  5.0366e-02,\n",
              "                      -3.3676e-01,  2.8367e-02, -2.2192e-02, -3.3649e-01, -2.4793e-01,\n",
              "                       3.0356e-01, -1.9083e-01, -2.0999e-01, -3.1039e-01,  1.2035e-01,\n",
              "                       9.7981e-02,  1.6812e-01, -4.6633e-02,  4.3348e-01, -1.3195e-01,\n",
              "                      -6.9714e-02, -5.3768e-01,  1.8806e-01, -2.1118e-01,  5.8075e-02,\n",
              "                      -2.6164e-01,  2.3446e-01, -4.0866e-01])),\n",
              "             ('transformer.layers.2.self_attn.in_proj_weight',\n",
              "              tensor([[-0.0016, -0.0120, -0.0986,  ...,  0.1520, -0.1188, -0.0346],\n",
              "                      [ 0.0406,  0.0180,  0.1472,  ...,  0.2154, -0.2008, -0.1650],\n",
              "                      [-0.1317, -0.0210, -0.0351,  ...,  0.0303,  0.2804,  0.0525],\n",
              "                      ...,\n",
              "                      [ 0.0148,  0.0033,  0.0913,  ..., -0.0724, -0.1477, -0.0393],\n",
              "                      [ 0.0268, -0.0194, -0.1262,  ...,  0.0713, -0.0818,  0.0349],\n",
              "                      [-0.0181, -0.0110,  0.1159,  ...,  0.0300,  0.1961,  0.1869]])),\n",
              "             ('transformer.layers.2.self_attn.in_proj_bias',\n",
              "              tensor([-2.4076e-02,  2.5624e-01,  1.0026e-01, -9.6611e-03, -3.7749e-02,\n",
              "                       4.2012e-02,  2.3974e-01,  1.1884e-01, -1.2204e-01, -2.9546e-02,\n",
              "                      -1.3122e-01,  3.8423e-01,  3.9580e-01, -2.7461e-01, -2.5810e-01,\n",
              "                       5.6397e-01,  2.2402e-01,  6.9401e-04, -3.3192e-01, -1.0363e-01,\n",
              "                       5.6391e-01,  2.2703e-01, -7.4804e-02, -1.5702e-01, -2.0846e-01,\n",
              "                       2.9574e-01,  5.8521e-02, -1.4999e-02,  4.5331e-01, -5.0590e-01,\n",
              "                       1.9464e-01, -2.9327e-01, -5.0194e-01,  8.0298e-01, -4.2244e-01,\n",
              "                      -6.5796e-01,  4.0743e-01, -3.5571e-01, -4.5972e-01, -3.9969e-01,\n",
              "                       4.3188e-02, -3.0005e-02, -2.1428e-01,  4.6667e-01, -2.0414e-01,\n",
              "                      -4.2119e-01, -3.0528e-01, -4.4891e-01,  9.9010e-02,  1.7288e-01,\n",
              "                      -2.2409e-01,  8.7742e-02, -1.2069e-01,  2.9953e-02,  1.5576e-01,\n",
              "                       1.2467e-01, -6.7251e-02, -1.3431e-01,  5.0517e-02, -9.9983e-02,\n",
              "                       8.2436e-02,  1.2579e-01,  4.8752e-02,  1.4053e-01,  2.1260e-01,\n",
              "                      -2.4810e-01, -6.4360e-01,  2.7649e-01, -1.2464e-01,  2.1192e-01,\n",
              "                      -4.5621e-01, -9.8830e-02,  1.2834e-01,  2.1439e-02, -6.8658e-01,\n",
              "                       1.5795e-01,  2.9684e-01, -1.9971e-01,  9.6816e-03, -5.8348e-01,\n",
              "                       4.2638e-01, -2.9465e-01,  4.9502e-01,  2.0063e-01,  7.6729e-02,\n",
              "                      -8.5793e-02,  5.0552e-01,  6.5522e-01,  1.8996e-01,  4.9718e-01,\n",
              "                       7.6051e-03, -1.8405e-01, -8.7735e-02,  2.6934e-01,  1.6256e-02,\n",
              "                       4.3013e-01,  4.1462e-02, -6.7063e-01, -4.4928e-01, -4.8895e-01,\n",
              "                       6.7865e-02,  2.4085e-01, -5.5764e-01,  2.2035e-01,  3.6307e-01,\n",
              "                      -7.5348e-01, -4.0612e-01, -2.1387e-01,  1.6309e-01,  6.2997e-02,\n",
              "                      -7.8107e-01,  1.2050e-01,  9.0498e-01,  2.5729e-01,  6.9681e-02,\n",
              "                      -7.2424e-01,  4.4614e-01,  3.7677e-01, -5.2715e-01, -3.6248e-02,\n",
              "                       1.9253e-01,  2.9269e-01,  4.3005e-01,  2.2173e-02,  1.0536e-01,\n",
              "                       2.6436e-01, -3.7336e-01, -2.8763e-02,  1.1165e-02,  2.2216e-03,\n",
              "                      -4.1099e-03, -8.3853e-03,  2.4855e-03, -6.8208e-03, -4.1964e-04,\n",
              "                       2.7469e-03,  3.2199e-03, -8.6817e-03, -1.9427e-02, -2.3061e-04,\n",
              "                       7.4543e-03,  4.1019e-03,  5.3066e-03, -2.1804e-03,  2.0688e-02,\n",
              "                       7.5906e-03,  6.2425e-03, -2.8935e-02,  1.4004e-02,  4.0096e-02,\n",
              "                      -1.4989e-02, -8.1555e-03,  1.6714e-02,  1.6611e-02,  8.9239e-03,\n",
              "                      -1.5924e-02,  2.9438e-02, -5.0145e-02, -4.4880e-03, -2.5759e-02,\n",
              "                      -3.4282e-03,  2.7840e-02, -1.0520e-02, -5.5891e-02,  1.5033e-02,\n",
              "                      -1.8956e-02, -2.7946e-02, -1.8650e-02, -2.2501e-03, -2.1976e-02,\n",
              "                       2.2309e-02, -8.3319e-03, -1.1167e-03,  9.8351e-03, -2.4515e-02,\n",
              "                       9.9626e-03,  2.8625e-04,  5.6230e-03,  7.0877e-04,  1.9236e-03,\n",
              "                      -2.8492e-03,  4.5389e-03,  1.7444e-02, -2.1489e-03, -1.1143e-02,\n",
              "                      -2.5006e-03, -1.1430e-03,  5.4106e-03,  2.8108e-03, -4.1156e-03,\n",
              "                       9.8041e-03,  9.2953e-03, -1.6123e-02, -1.0273e-02, -1.6469e-02,\n",
              "                      -1.0523e-02, -7.9445e-03, -3.9576e-03, -1.6837e-02, -2.2086e-02,\n",
              "                       4.5372e-03, -2.8657e-02, -2.4521e-02,  8.7683e-03,  1.1822e-02,\n",
              "                       7.3759e-03,  2.1099e-03,  3.6894e-03,  2.0478e-02, -2.9909e-02,\n",
              "                       1.4947e-05, -6.3005e-03, -7.1251e-03, -2.9724e-02,  2.6729e-02,\n",
              "                       3.2965e-03,  1.0352e-02,  2.1169e-03,  7.4858e-03, -6.8097e-03,\n",
              "                       1.0316e-02,  5.3494e-03,  1.8337e-03,  7.0116e-03, -6.2866e-03,\n",
              "                      -3.2403e-02, -4.5973e-02, -1.4009e-02,  5.8390e-03,  5.4471e-04,\n",
              "                      -7.5781e-02, -2.8546e-02, -2.7094e-03, -5.2173e-02, -3.2612e-02,\n",
              "                      -4.8710e-02,  3.1825e-02,  7.4457e-03, -4.7416e-02,  1.9562e-02,\n",
              "                      -2.3839e-02, -8.7044e-03,  5.7091e-03, -4.8590e-03, -1.0297e-02,\n",
              "                       1.9218e-02,  2.3655e-02,  3.2299e-02,  1.0934e-02, -2.5221e-02,\n",
              "                       5.9103e-03, -3.0347e-02, -4.2555e-02, -4.7223e-03,  3.3111e-03,\n",
              "                       2.6151e-02, -1.1481e-02,  4.3771e-02,  8.8651e-04,  2.5641e-02,\n",
              "                       6.4538e-03, -1.3270e-02,  5.4362e-02, -1.2311e-02, -5.7706e-02,\n",
              "                      -2.4319e-02, -1.2423e-02,  6.1660e-02, -6.9307e-03,  5.0522e-02,\n",
              "                       1.4817e-02,  6.8111e-02, -1.4774e-01, -3.8708e-02, -7.7093e-02,\n",
              "                       6.4532e-02, -6.6106e-02, -1.4095e-02,  6.1091e-02, -9.5036e-03,\n",
              "                       8.4742e-02, -1.4519e-01, -4.2624e-02,  4.0833e-02, -4.6595e-02,\n",
              "                       3.0409e-02,  1.1045e-02,  1.4038e-02, -1.2198e-02, -1.6840e-02,\n",
              "                       3.2017e-02,  5.2708e-02, -1.0697e-01,  1.9997e-02,  3.5176e-02,\n",
              "                      -8.4955e-02, -1.7778e-02,  4.5879e-02, -9.0541e-02, -1.0799e-02,\n",
              "                       5.6640e-02, -5.6886e-02,  5.2425e-02,  2.0359e-02, -5.4119e-02,\n",
              "                       2.0958e-02, -6.4905e-03, -4.0563e-02,  8.9009e-02, -9.8939e-02,\n",
              "                       1.3053e-02,  3.0788e-02, -1.3178e-01,  7.8212e-02,  1.7368e-03,\n",
              "                      -2.5022e-02, -1.1527e-02, -2.4846e-02,  1.2047e-03, -2.0920e-02,\n",
              "                       3.0780e-02, -2.4566e-02, -9.7171e-02,  9.3648e-02,  2.4246e-02,\n",
              "                       1.8917e-02,  9.0025e-02,  3.8229e-02,  9.1842e-02, -7.7837e-02,\n",
              "                      -1.2380e-02,  5.5288e-02, -1.9891e-02, -4.6252e-03,  6.7390e-02,\n",
              "                       4.6051e-02, -7.1750e-02, -1.8114e-02, -8.0513e-02,  3.2890e-02,\n",
              "                       3.7333e-02, -4.8440e-02,  1.9183e-02, -1.2788e-02,  9.2611e-03,\n",
              "                      -1.2945e-02, -6.3812e-02,  6.9734e-02,  9.3036e-03,  1.9411e-03,\n",
              "                       9.7371e-02, -1.5238e-02,  5.5841e-02,  1.7103e-01, -1.2006e-01,\n",
              "                       4.7553e-02,  3.0023e-03,  9.9843e-02, -5.0498e-02, -5.8102e-03,\n",
              "                       7.3055e-03,  5.5061e-02, -3.5402e-02, -8.1459e-02, -1.8981e-01,\n",
              "                       4.2455e-03,  1.8544e-01, -8.4811e-02, -1.2505e-01, -4.3529e-02,\n",
              "                       1.2667e-01, -8.6386e-02, -6.5567e-02,  4.7535e-02,  3.0544e-02,\n",
              "                       4.6828e-02, -2.9707e-02, -8.7724e-02, -1.4316e-02, -7.6717e-03,\n",
              "                       1.5570e-02, -1.0811e-02, -3.8279e-02,  4.3567e-03])),\n",
              "             ('transformer.layers.2.self_attn.out_proj.weight',\n",
              "              tensor([[ 0.0120, -0.0420, -0.0691,  ..., -0.0212,  0.0795,  0.0266],\n",
              "                      [ 0.0084,  0.0497, -0.0313,  ...,  0.0465, -0.0108, -0.0345],\n",
              "                      [-0.0054, -0.0152, -0.0799,  ...,  0.1356, -0.1667,  0.1342],\n",
              "                      ...,\n",
              "                      [-0.1147,  0.0177,  0.0471,  ..., -0.0109, -0.0402, -0.0790],\n",
              "                      [ 0.0076,  0.0662, -0.1325,  ...,  0.1251, -0.0145,  0.0543],\n",
              "                      [-0.1318, -0.0498, -0.0015,  ...,  0.0122,  0.0421,  0.1670]])),\n",
              "             ('transformer.layers.2.self_attn.out_proj.bias',\n",
              "              tensor([-4.2146e-02, -2.2010e-02,  2.0324e-01, -1.1020e-02, -6.4497e-02,\n",
              "                       6.3069e-02,  1.5489e-01, -1.1827e-01,  5.3947e-02,  9.7600e-02,\n",
              "                      -1.4910e-01,  1.0972e-01,  3.9160e-02,  1.0002e-01,  4.8025e-02,\n",
              "                      -4.6784e-02,  5.0796e-02,  6.4491e-03,  7.4147e-02,  4.9559e-02,\n",
              "                       2.0612e-02,  5.8388e-02,  6.4326e-02,  5.8844e-03, -1.0107e-03,\n",
              "                      -2.6717e-02, -1.1418e-01,  1.0777e-03,  2.7418e-02, -1.2896e-01,\n",
              "                       1.1207e-01, -6.5747e-02, -8.9357e-02, -1.3580e-04, -6.7328e-03,\n",
              "                       5.2817e-02,  2.0242e-02, -1.0761e-01, -1.9294e-02,  9.9227e-02,\n",
              "                       6.1457e-03,  1.2432e-01,  7.3427e-02, -4.6960e-02, -1.1056e-01,\n",
              "                       3.2969e-03, -5.7900e-02, -1.4331e-02, -3.6730e-02, -8.2229e-02,\n",
              "                      -4.7724e-02, -7.9471e-02,  7.6637e-02,  2.8025e-03, -1.2169e-02,\n",
              "                      -1.1444e-02,  1.3765e-02, -1.4567e-01,  2.5970e-02,  1.9558e-02,\n",
              "                       1.0482e-01,  2.7972e-02, -1.5108e-02,  6.9240e-02, -1.2906e-02,\n",
              "                       2.1227e-02,  8.5623e-02,  1.2830e-02, -9.5978e-03,  8.4927e-02,\n",
              "                      -1.1815e-01,  5.4302e-02,  3.3107e-02, -3.6484e-04, -9.6607e-02,\n",
              "                       4.2207e-02,  1.2641e-01, -1.8998e-02,  1.2513e-02,  5.3946e-02,\n",
              "                       6.3723e-02, -1.4387e-01, -1.6821e-02,  9.8109e-02,  3.2816e-02,\n",
              "                      -3.0440e-01,  3.0425e-02, -1.1621e-01, -6.7556e-02, -1.1189e-02,\n",
              "                       8.7615e-04,  8.3486e-02,  3.0362e-02, -7.2234e-02,  7.5802e-03,\n",
              "                       1.4340e-01, -1.8323e-01,  3.4762e-02,  1.4800e-02, -4.1341e-02,\n",
              "                      -5.0798e-02,  5.8435e-02,  1.3974e-01, -1.2891e-01, -7.2516e-02,\n",
              "                       2.8650e-02,  1.0926e-01, -1.5413e-01,  1.1670e-01,  1.6321e-01,\n",
              "                       7.5238e-02,  8.8755e-02, -9.8831e-02,  1.4553e-02,  2.0332e-02,\n",
              "                       3.2278e-02, -4.3800e-02, -1.7594e-02,  2.6165e-02,  2.4524e-02,\n",
              "                       4.6415e-02,  5.4903e-02, -1.2500e-01, -4.2080e-02,  1.4496e-01,\n",
              "                       1.2688e-01, -8.2332e-02, -1.2296e-01])),\n",
              "             ('transformer.layers.2.linear1.weight',\n",
              "              tensor([[ 8.7052e-02, -9.9739e-03,  1.1001e-01,  ..., -1.9904e-01,\n",
              "                       -3.3248e-01,  1.5100e-01],\n",
              "                      [ 5.1167e-02, -3.8670e-02, -4.5862e-02,  ..., -3.4091e-01,\n",
              "                       -1.0834e-01, -1.6614e-01],\n",
              "                      [ 1.0684e-01, -6.6144e-02,  2.4450e-01,  ..., -2.7580e-01,\n",
              "                        2.8042e-01, -1.3682e-01],\n",
              "                      ...,\n",
              "                      [ 2.8294e-02, -2.3834e-02,  2.9425e-01,  ..., -1.7821e-01,\n",
              "                        4.1207e-02, -1.0758e-01],\n",
              "                      [ 2.9787e-02, -4.6844e-02,  2.2983e-01,  ..., -3.2832e-02,\n",
              "                        1.2654e-01, -1.8916e-01],\n",
              "                      [ 9.3132e-02,  1.3406e-04,  1.8886e-01,  ...,  2.8458e-02,\n",
              "                        9.2548e-02, -4.8196e-01]])),\n",
              "             ('transformer.layers.2.linear1.bias',\n",
              "              tensor([-0.2942, -0.2108, -0.3066, -0.3382, -0.3001, -0.2938, -0.2868, -0.3370,\n",
              "                      -0.2157, -0.2838, -0.2294, -0.3507, -0.3183, -0.3457, -0.1941, -0.2981,\n",
              "                      -0.2837, -0.2243, -0.4556, -0.2561, -0.3284, -0.3154, -0.2284, -0.2324,\n",
              "                      -0.2924, -0.3670, -0.3773, -0.0729, -0.2496, -0.2185, -0.2470, -0.0822,\n",
              "                      -0.2827, -0.2447, -0.1990, -0.2407, -0.3974, -0.3838, -0.0723, -0.0166,\n",
              "                      -0.4224, -0.2748, -0.2228, -0.3794, -0.2609, -0.2874, -0.2059, -0.3212,\n",
              "                      -0.2954, -0.3762, -0.2651, -0.3071, -0.3737, -0.3496, -0.4428, -0.2372,\n",
              "                      -0.3115, -0.1533, -0.1934, -0.4263, -0.1036, -0.2686, -0.3287, -0.4171,\n",
              "                      -0.3617, -0.3377, -0.2615, -0.4202, -0.2057, -0.1850, -0.3066, -0.2974,\n",
              "                      -0.4220, -0.2161, -0.3361, -0.4754, -0.0744, -0.4012, -0.2892, -0.1955,\n",
              "                      -0.3722, -0.4369, -0.1949, -0.2986, -0.2899, -0.0576, -0.3165, -0.2616,\n",
              "                      -0.1943, -0.2268, -0.2197, -0.4184, -0.2342, -0.3601, -0.3005, -0.2057,\n",
              "                      -0.0936, -0.2538, -0.2597, -0.2825, -0.4840, -0.2548, -0.0548, -0.3232,\n",
              "                      -0.3052, -0.3355, -0.2158, -0.2688, -0.2394, -0.3032, -0.2690, -0.2543,\n",
              "                      -0.2711, -0.1214, -0.4439, -0.4533, -0.1657, -0.2560, -0.1420, -0.2764,\n",
              "                      -0.1947, -0.2735, -0.1648, -0.2115, -0.2153, -0.3384, -0.3173, -0.1273,\n",
              "                      -0.0735, -0.3807, -0.3327, -0.3129, -0.3233, -0.1759, -0.2126, -0.3148,\n",
              "                      -0.3251, -0.4146, -0.5179, -0.1789, -0.5964, -0.2830, -0.3518, -0.2892,\n",
              "                      -0.4128, -0.3606, -0.2278, -0.3563, -0.2844, -0.1219, -0.2326, -0.2558,\n",
              "                      -0.2392, -0.3874, -0.2858, -0.1242, -0.3769, -0.3448, -0.2485, -0.2054,\n",
              "                      -0.3111, -0.4159, -0.2027, -0.3286, -0.2319, -0.3145, -0.2709, -0.1212,\n",
              "                      -0.1450, -0.2727, -0.2720, -0.3939, -0.2963, -0.2582, -0.3233, -0.4807,\n",
              "                      -0.2948, -0.1649, -0.2894, -0.1057, -0.2367, -0.3492, -0.2922, -0.1791,\n",
              "                      -0.3279, -0.3714, -0.2858, -0.2329, -0.2498, -0.3447, -0.2949, -0.3126,\n",
              "                      -0.3224, -0.1829, -0.3390, -0.1677, -0.3814, -0.3270, -0.0711, -0.1837,\n",
              "                      -0.3234, -0.2111, -0.2462, -0.3202, -0.0919, -0.1759, -0.1762, -0.1827,\n",
              "                      -0.4736, -0.2017, -0.2144, -0.3618, -0.3642, -0.1973, -0.4763, -0.3857,\n",
              "                      -0.1952, -0.2249, -0.2792, -0.2494, -0.3437, -0.2928, -0.3422, -0.3651,\n",
              "                      -0.2999, -0.2153, -0.2110, -0.2469, -0.3980, -0.2005, -0.3965, -0.2645,\n",
              "                      -0.3182, -0.2477, -0.3726, -0.2844, -0.3536, -0.3231, -0.2766, -0.2147,\n",
              "                      -0.4149, -0.2532, -0.2011, -0.2897, -0.3189, -0.2656, -0.3854, -0.2113,\n",
              "                      -0.3879, -0.3739, -0.3730, -0.4394, -0.2960, -0.3636, -0.2048, -0.3161])),\n",
              "             ('transformer.layers.2.linear2.weight',\n",
              "              tensor([[-0.0376,  0.0462,  0.1021,  ..., -0.0040, -0.0094,  0.0938],\n",
              "                      [ 0.0564, -0.0435,  0.0030,  ..., -0.0491,  0.0099, -0.0384],\n",
              "                      [ 0.0150,  0.0737,  0.0259,  ..., -0.1183, -0.0786,  0.1288],\n",
              "                      ...,\n",
              "                      [ 0.2828, -0.0240, -0.0377,  ..., -0.1204, -0.0412, -0.0420],\n",
              "                      [-0.0701,  0.1699, -0.0333,  ..., -0.1185, -0.1522, -0.0388],\n",
              "                      [ 0.1041, -0.2033, -0.0114,  ..., -0.0980,  0.2423, -0.1831]])),\n",
              "             ('transformer.layers.2.linear2.bias',\n",
              "              tensor([ 0.0585, -0.0082,  0.0329, -0.1147,  0.0707, -0.0483, -0.0457, -0.0106,\n",
              "                      -0.0846,  0.1447, -0.1407, -0.0698, -0.0275,  0.0992,  0.0665, -0.0584,\n",
              "                      -0.0261,  0.1228,  0.2373, -0.0481, -0.1112,  0.0867,  0.1373,  0.0624,\n",
              "                      -0.0365, -0.0038, -0.2171,  0.1694,  0.0474, -0.0449,  0.3409, -0.1541,\n",
              "                      -0.0091,  0.1154, -0.1356,  0.1513,  0.1447, -0.2552, -0.0610,  0.1206,\n",
              "                      -0.0340,  0.2192,  0.0191, -0.2121,  0.0955,  0.1593,  0.0686, -0.1822,\n",
              "                      -0.0797, -0.0969,  0.3670, -0.0419, -0.0371,  0.1649, -0.1445, -0.1800,\n",
              "                      -0.0756,  0.2110, -0.0413,  0.1053,  0.1095, -0.3267, -0.2783, -0.0316,\n",
              "                       0.0540, -0.0806,  0.0263, -0.1827,  0.0675,  0.0482, -0.1214, -0.0648,\n",
              "                       0.2217,  0.0550,  0.2367, -0.0545, -0.0032, -0.0219,  0.0219,  0.2008,\n",
              "                       0.0022, -0.1127, -0.1676, -0.0125, -0.0059,  0.0408, -0.0288, -0.5112,\n",
              "                      -0.0201,  0.1051, -0.0760,  0.0874,  0.1725, -0.3109,  0.0518, -0.1150,\n",
              "                      -0.3700,  0.1341, -0.0903, -0.0472,  0.0817, -0.0983,  0.0838,  0.0288,\n",
              "                      -0.1387, -0.0180, -0.1236,  0.0603,  0.1705, -0.0661, -0.0233, -0.0832,\n",
              "                      -0.0710, -0.1715,  0.0130, -0.0228, -0.0202, -0.1043, -0.1477, -0.0204,\n",
              "                       0.3413,  0.1127,  0.1287, -0.0475, -0.1673,  0.1084,  0.0081,  0.0861])),\n",
              "             ('transformer.layers.2.norm1.weight',\n",
              "              tensor([0.7341, 0.7118, 0.6122, 0.5534, 0.3583, 0.4339, 0.3943, 0.5725, 0.5492,\n",
              "                      0.4918, 0.7473, 0.8184, 1.6490, 1.6867, 0.5701, 0.8086, 0.7924, 0.8919,\n",
              "                      1.1248, 1.8307, 1.9091, 1.8670, 1.0209, 1.3083, 0.9686, 0.7665, 0.7038,\n",
              "                      0.8265, 0.8647, 0.9530, 1.2545, 1.2597, 0.9593, 1.0077, 1.0362, 1.4930,\n",
              "                      0.9493, 1.4369, 1.0010, 1.1498, 1.1425, 1.1198, 0.7970, 1.0217, 1.2051,\n",
              "                      0.9380, 1.0032, 0.9893, 0.5007, 0.9478, 1.0444, 0.9548, 0.7210, 1.1250,\n",
              "                      0.8241, 0.8125, 0.8868, 0.7479, 0.8515, 0.7014, 0.8412, 0.8415, 0.8046,\n",
              "                      0.8502, 0.8290, 0.8586, 1.1304, 0.7414, 0.7295, 0.7285, 0.8927, 0.8517,\n",
              "                      0.9426, 0.6926, 0.6795, 0.8364, 0.4979, 1.0031, 0.8656, 0.6694, 0.8384,\n",
              "                      0.6537, 0.8673, 0.8508, 0.9146, 0.6676, 0.9025, 0.9060, 0.7506, 1.1632,\n",
              "                      0.7506, 0.8654, 0.8912, 0.6634, 0.7225, 0.8172, 0.6885, 0.5785, 1.1282,\n",
              "                      0.5841, 0.7210, 0.7196, 0.7288, 0.8531, 0.8788, 0.7917, 0.8074, 0.8078,\n",
              "                      0.6525, 0.7130, 0.7921, 0.6006, 0.7698, 0.7172, 0.8359, 0.8287, 0.9138,\n",
              "                      0.6896, 0.7390, 0.8715, 0.7631, 0.6426, 0.7229, 0.8448, 0.9650, 0.7088,\n",
              "                      0.8231, 0.6802])),\n",
              "             ('transformer.layers.2.norm1.bias',\n",
              "              tensor([-1.0025e-01,  5.5775e-01, -2.8598e-01, -2.0769e-01, -7.5860e-03,\n",
              "                      -8.6843e-01,  4.6214e-02, -6.7370e-02, -1.8745e-01,  3.0549e-01,\n",
              "                      -1.0766e-01, -1.3551e-01, -2.1401e-01, -6.1590e-01,  3.5721e-01,\n",
              "                      -1.7739e-01, -2.4898e-01, -3.4712e-01, -4.2781e-01, -4.5062e-01,\n",
              "                       2.6825e-01, -1.9276e-01, -2.9510e-01, -8.0018e-01,  3.0129e-01,\n",
              "                      -4.2702e-01,  2.6560e-03, -1.2377e+00, -4.1087e-02, -8.8947e-03,\n",
              "                      -2.0598e-01, -6.9879e-01, -2.4193e-02,  2.1477e-01, -4.6047e-02,\n",
              "                       9.2141e-01, -2.8416e-01, -2.6858e-01,  4.5384e-02, -1.1595e-01,\n",
              "                       2.1298e-01, -5.2668e-01, -4.1894e-01, -3.4503e-01, -9.2159e-03,\n",
              "                       2.0510e-01,  5.8629e-01,  8.5779e-02, -1.0728e-01, -1.3800e-01,\n",
              "                       4.1585e-02, -2.8406e-01,  3.0871e-01,  2.7693e-01,  1.5484e-01,\n",
              "                       1.1881e+00, -6.2518e-02, -1.7194e-01, -3.8266e-01,  1.5372e-01,\n",
              "                      -5.4271e-02,  2.6592e-01,  3.1898e-01, -2.8559e-01,  1.3511e-01,\n",
              "                       5.9175e-01,  9.0087e-02,  4.6299e-01,  2.4646e-01,  1.0264e-01,\n",
              "                      -8.9138e-02,  6.5246e-01, -2.2752e-01,  8.1110e-01,  1.0379e-01,\n",
              "                       1.6613e-01, -2.1290e-01,  3.1757e-01, -2.6170e-01,  2.1347e-01,\n",
              "                       5.3624e-01,  3.3436e-01,  7.6269e-01, -1.4735e-01,  7.5298e-02,\n",
              "                      -9.9374e-02, -3.0408e-01, -1.5455e+00,  4.3813e-01, -3.4140e-01,\n",
              "                      -5.6809e-01,  9.6867e-02, -1.6583e-02,  5.1545e-02,  6.1398e-02,\n",
              "                       4.3350e-02, -9.5106e-01, -5.2288e-01, -3.2227e-01,  1.4536e-01,\n",
              "                      -2.0350e-01,  4.8059e-01, -1.0700e-01,  3.3572e-01, -1.0600e-01,\n",
              "                       9.9172e-02, -1.5841e-01, -1.7110e-02,  6.2150e-01,  1.7443e-01,\n",
              "                      -4.6042e-04, -2.8856e-01,  5.5357e-01,  1.8224e-01, -2.3291e-02,\n",
              "                       2.6924e-02, -2.7615e-01, -2.1609e-01, -8.1919e-01,  5.5629e-02,\n",
              "                       4.8765e-01,  2.0303e-01, -9.2106e-02,  1.3053e-01,  5.4708e-03,\n",
              "                       2.0791e-01, -3.1899e-01,  7.2163e-01])),\n",
              "             ('transformer.layers.2.norm2.weight',\n",
              "              tensor([0.9052, 0.9526, 0.6091, 0.5404, 0.6178, 0.4743, 0.5182, 0.6371, 0.6127,\n",
              "                      0.5656, 0.6962, 0.5416, 0.5801, 0.5697, 0.6987, 0.6753, 0.6080, 0.4627,\n",
              "                      0.5247, 0.4350, 0.4838, 0.5298, 0.5917, 0.4680, 0.6158, 0.6322, 0.5920,\n",
              "                      0.4717, 0.6203, 0.5640, 0.4939, 0.5945, 0.7152, 0.7214, 0.6049, 0.5170,\n",
              "                      0.6292, 0.5066, 0.5727, 0.6198, 0.5538, 0.5448, 0.6658, 0.6116, 0.5599,\n",
              "                      0.6841, 0.7221, 0.5955, 0.5264, 0.7357, 0.7359, 0.6288, 0.5480, 0.6372,\n",
              "                      0.7136, 0.5892, 0.7321, 0.6416, 0.7554, 0.7880, 0.6844, 0.7260, 0.6777,\n",
              "                      0.6353, 0.6928, 0.7824, 0.7022, 0.7205, 0.6964, 0.6045, 0.6640, 0.6552,\n",
              "                      0.6504, 0.5957, 0.6329, 0.7375, 0.6350, 0.7564, 0.7103, 0.6732, 0.6025,\n",
              "                      0.5828, 0.6465, 0.6509, 0.6950, 0.8036, 0.6982, 0.3527, 0.7110, 0.8425,\n",
              "                      0.7203, 0.6788, 0.6744, 0.5256, 0.6850, 0.7348, 0.4610, 0.6461, 0.6859,\n",
              "                      0.5923, 0.5939, 0.5703, 0.5977, 0.7462, 0.6615, 0.6427, 0.6807, 0.6914,\n",
              "                      0.6037, 0.6661, 0.7043, 0.6923, 0.7760, 0.6522, 0.6705, 0.6769, 0.7382,\n",
              "                      0.6449, 0.5726, 0.6448, 0.7097, 0.5705, 0.6584, 0.6466, 0.6269, 0.6727,\n",
              "                      0.6514, 0.6293])),\n",
              "             ('transformer.layers.2.norm2.bias',\n",
              "              tensor([ 0.0208, -0.4009,  0.1347,  0.0920, -0.0074,  0.2748, -0.0130, -0.0367,\n",
              "                       0.1123, -0.1981,  0.1495,  0.0273,  0.0389,  0.2205, -0.2300,  0.0592,\n",
              "                       0.1225,  0.1181,  0.2124,  0.2132, -0.0038, -0.0624,  0.1333,  0.2234,\n",
              "                      -0.1662,  0.1885,  0.0406,  0.3887, -0.0149,  0.0296,  0.0614,  0.4452,\n",
              "                       0.1165, -0.1341,  0.0435, -0.5536,  0.1398,  0.2121, -0.0320, -0.0038,\n",
              "                      -0.0813,  0.0810,  0.1668,  0.2307,  0.0591, -0.1391, -0.3966, -0.0621,\n",
              "                       0.0590,  0.1499, -0.0396,  0.1837, -0.0870, -0.1974, -0.0743, -0.1930,\n",
              "                      -0.0633,  0.0966,  0.2223, -0.1552, -0.0522, -0.1303, -0.1696,  0.1195,\n",
              "                      -0.0891, -0.3719, -0.1784, -0.2113, -0.1626, -0.0795,  0.0233, -0.4285,\n",
              "                       0.0354, -0.4577, -0.0458, -0.1066,  0.1067, -0.2376,  0.0684, -0.1854,\n",
              "                      -0.2436, -0.1546, -0.3336,  0.0241, -0.0995,  0.0904,  0.1331,  0.3585,\n",
              "                      -0.2424,  0.1100,  0.2758, -0.1283, -0.0321,  0.0185, -0.0216, -0.0396,\n",
              "                       0.4040,  0.2025,  0.2077, -0.0856,  0.0752, -0.2607,  0.0272, -0.2820,\n",
              "                       0.0470, -0.0724, -0.0066,  0.0082, -0.3544, -0.1284,  0.0059,  0.1119,\n",
              "                      -0.2859, -0.1006, -0.0215, -0.0302,  0.1847,  0.1657,  0.3927, -0.1059,\n",
              "                      -0.3077, -0.1040,  0.0491, -0.0311, -0.0650, -0.1740,  0.2118, -0.3862])),\n",
              "             ('transformer.layers.3.self_attn.in_proj_weight',\n",
              "              tensor([[ 0.0131, -0.0873,  0.0685,  ...,  0.2063, -0.0301, -0.0822],\n",
              "                      [ 0.0083,  0.0497, -0.0663,  ...,  0.1850, -0.1253,  0.0651],\n",
              "                      [-0.0082,  0.1489, -0.0294,  ..., -0.0394,  0.0141,  0.2902],\n",
              "                      ...,\n",
              "                      [-0.0309, -0.0572,  0.0018,  ...,  0.0731, -0.0210,  0.0934],\n",
              "                      [-0.0120, -0.0709, -0.2800,  ..., -0.0712, -0.0346, -0.1818],\n",
              "                      [ 0.0204,  0.0147, -0.1233,  ..., -0.0139, -0.1975,  0.1721]])),\n",
              "             ('transformer.layers.3.self_attn.in_proj_bias',\n",
              "              tensor([ 7.4263e-02,  5.8698e-01,  3.6954e-02, -2.1540e-01, -1.0680e-01,\n",
              "                       5.2220e-01, -1.9221e-01, -2.2365e-01, -7.1312e-01, -6.9913e-03,\n",
              "                       7.9410e-02,  1.5675e-01,  1.8934e-01, -1.7358e-02, -2.9424e-01,\n",
              "                      -7.1954e-02,  2.4658e-01,  2.1813e-02, -4.8554e-01,  7.0387e-02,\n",
              "                      -1.5501e-01, -8.9180e-03,  2.2047e-01,  3.5016e-01,  1.8852e-01,\n",
              "                      -1.1931e-01,  8.0669e-02,  5.7097e-01,  2.8891e-01,  4.7775e-02,\n",
              "                      -7.6831e-02, -2.0910e-01,  2.3680e-01, -5.5290e-02, -2.9952e-01,\n",
              "                      -3.6497e-02, -2.1855e-01,  1.7404e-04, -1.9775e-01, -3.3203e-01,\n",
              "                      -1.9562e-01, -5.0859e-02, -1.4494e-01,  6.6856e-02, -2.9448e-01,\n",
              "                       1.7363e-01, -2.7307e-02,  2.6547e-02,  2.7743e-02,  3.1544e-01,\n",
              "                      -3.9111e-02, -1.7895e-01,  1.2962e-02,  1.3238e-01, -9.7883e-01,\n",
              "                       1.7388e-01,  4.6097e-01, -3.5576e-02, -2.3254e-02,  1.3912e-01,\n",
              "                       3.0748e-01,  2.9204e-01, -6.4713e-02,  7.5488e-04, -4.7352e-01,\n",
              "                      -1.2759e-01,  2.0475e-01,  1.0565e-01,  6.3335e-02,  1.7884e-01,\n",
              "                      -2.5650e-01, -1.8919e-01, -2.1483e-02,  8.1311e-02,  1.7527e-01,\n",
              "                      -1.6078e-01, -7.8308e-03,  6.9137e-02, -1.2207e-01, -2.2857e-01,\n",
              "                      -1.7257e-01, -1.2044e+00, -9.0477e-02,  8.5205e-02, -2.9723e-01,\n",
              "                      -1.1097e-01,  9.5108e-02, -1.9126e-02, -6.7176e-02,  9.9739e-02,\n",
              "                      -3.6808e-01, -1.2473e-02,  2.6490e-01,  2.5364e-01, -2.2275e-01,\n",
              "                       1.6740e-01,  2.8309e-01, -3.2449e-01, -1.0709e-01,  2.9669e-01,\n",
              "                       1.4046e-01, -9.2936e-02, -5.5526e-01, -2.5688e-01, -1.3840e-01,\n",
              "                      -1.3458e-01,  6.9828e-03, -1.5122e-01, -3.3027e-01,  1.9619e-01,\n",
              "                       1.1362e-01,  1.0350e-01,  7.0109e-02, -2.8403e-01, -9.2389e-03,\n",
              "                      -5.8882e-02, -5.8869e-02,  1.7310e-01,  1.9529e-01, -1.7898e-01,\n",
              "                      -9.2921e-02, -2.0098e-01,  4.9903e-01, -1.8290e-01,  1.4454e-02,\n",
              "                      -3.2395e-01,  1.0822e-01,  1.7035e-01,  1.0556e-01,  2.8814e-01,\n",
              "                       1.9399e-01, -1.3389e-01,  5.0051e-02,  2.5547e-01,  7.7980e-02,\n",
              "                      -2.9277e-02, -2.6473e-01, -1.3071e-01,  3.3881e-02,  1.6303e-01,\n",
              "                       1.0050e-01,  3.1367e-02, -9.5490e-02,  1.5302e-01,  4.0948e-02,\n",
              "                      -1.8930e-02, -8.0699e-02,  2.3987e-02,  2.1029e-03,  8.7874e-03,\n",
              "                       4.3144e-02,  1.7417e-02,  4.2394e-03,  4.6822e-02,  4.2171e-02,\n",
              "                       2.1146e-02,  6.8983e-02,  4.3467e-02, -5.8621e-03, -1.6032e-02,\n",
              "                       5.8542e-02, -1.0976e-01, -6.4220e-02, -2.1596e-02, -1.1493e-03,\n",
              "                      -1.0792e-01, -5.6167e-02, -3.3038e-02, -4.3035e-02, -3.7541e-02,\n",
              "                      -3.3669e-02,  8.8266e-02, -3.8057e-02,  2.4154e-02, -1.5556e-02,\n",
              "                      -5.0666e-02, -2.1958e-02, -3.6189e-02,  3.4692e-02,  3.8915e-02,\n",
              "                      -1.6163e-02,  4.0694e-02,  1.3871e-02,  2.0615e-02, -4.4113e-03,\n",
              "                       6.1562e-03,  1.6078e-02,  2.7797e-02, -5.4606e-02, -1.6092e-02,\n",
              "                       3.6771e-02,  4.6218e-03, -1.0295e-02,  5.9797e-05,  1.2593e-02,\n",
              "                       2.1466e-03,  6.2667e-03,  4.8538e-03, -4.8780e-03, -6.0403e-03,\n",
              "                       1.1368e-03,  1.7692e-03,  3.2148e-03, -2.5195e-03, -1.1875e-03,\n",
              "                      -1.0908e-03,  5.2429e-04, -4.5725e-03,  1.1842e-02, -1.6740e-01,\n",
              "                      -1.2733e-03,  4.4381e-03, -5.2855e-02, -3.7667e-03, -4.2992e-02,\n",
              "                       4.6085e-03,  3.9393e-03,  2.0852e-02,  2.2850e-02, -8.9498e-04,\n",
              "                       2.8365e-02,  5.8793e-02, -3.6767e-02,  1.3066e-02,  7.8374e-03,\n",
              "                      -3.2288e-02, -2.6137e-02, -1.8553e-02,  2.0933e-03,  1.8360e-02,\n",
              "                       9.9320e-03,  3.8159e-03,  4.7131e-03, -9.4027e-03, -2.6187e-02,\n",
              "                       1.5676e-02, -8.6628e-03,  1.0281e-02, -2.5165e-03, -1.6248e-02,\n",
              "                       2.2148e-02, -1.6561e-02, -2.2459e-02, -2.1640e-02, -2.8461e-02,\n",
              "                       6.0382e-02, -2.6950e-04,  2.9131e-02,  2.2591e-02, -5.5804e-03,\n",
              "                       7.6037e-02, -2.3552e-02, -4.5104e-03, -3.1326e-02, -1.0538e-01,\n",
              "                      -1.3764e-02, -9.9118e-02, -1.4367e-02, -1.4140e-01,  2.4416e-02,\n",
              "                       6.3779e-02, -1.1442e-01, -3.2414e-02, -4.7574e-02, -1.8611e-02,\n",
              "                       1.7037e-02,  1.8616e-02,  8.9989e-02, -5.0326e-02, -9.5377e-02,\n",
              "                      -1.2749e-02, -8.4644e-02,  1.1107e-01,  3.5920e-02,  3.4431e-02,\n",
              "                      -3.9843e-02, -1.6949e-01, -4.7574e-03,  1.5378e-02,  4.3040e-02,\n",
              "                       5.0049e-02, -1.3874e-02, -1.0230e-01,  5.4993e-02,  8.9872e-02,\n",
              "                       2.1591e-02, -4.2266e-02,  1.7471e-01,  4.0436e-02,  3.3680e-03,\n",
              "                      -1.5656e-02,  9.8810e-02, -1.1293e-01, -1.2041e-01,  2.0326e-02,\n",
              "                       1.4736e-01,  5.2664e-02,  9.7752e-02,  5.8972e-02, -1.9944e-02,\n",
              "                       5.0089e-02,  2.5118e-02,  6.5069e-02,  1.3850e-02,  2.7024e-02,\n",
              "                       2.0969e-02,  9.1040e-02, -1.3012e-01,  1.1704e-01,  6.6809e-02,\n",
              "                      -6.0690e-02,  1.7418e-02, -1.9985e-01, -8.9996e-03, -7.2810e-03,\n",
              "                      -1.2886e-02,  6.6690e-02, -1.4763e-02,  5.9215e-02,  7.5309e-02,\n",
              "                       2.6693e-02, -5.2845e-02, -6.8764e-03,  1.3454e-02,  6.9656e-02,\n",
              "                       6.6954e-03, -5.5517e-02, -1.5708e-02,  6.7496e-03,  1.6384e-02,\n",
              "                      -7.9904e-03,  8.4382e-02,  8.0587e-02, -6.1191e-03,  3.0585e-02,\n",
              "                       2.5506e-02, -3.6560e-02,  3.9768e-02, -5.6320e-02,  5.3813e-02,\n",
              "                       9.9118e-02,  1.8299e-02,  2.9566e-02,  7.7377e-02,  4.2211e-02,\n",
              "                      -1.1528e-02,  3.1385e-02, -1.3575e-02, -5.9380e-02, -1.0529e-02,\n",
              "                       5.5382e-02,  4.8227e-03,  3.2421e-02,  1.5814e-02, -1.9917e-01,\n",
              "                      -1.3835e-01, -7.9335e-02,  6.9255e-02,  1.3824e-02, -9.7172e-03,\n",
              "                       1.2317e-02, -1.0874e-02,  1.5116e-02, -2.9814e-02, -7.5548e-04,\n",
              "                      -8.9602e-02, -3.5611e-03, -2.5208e-02, -5.2477e-02, -2.3267e-03,\n",
              "                      -4.5475e-02,  6.0962e-03,  1.4695e-02,  1.0694e-01,  6.5289e-02,\n",
              "                       7.8140e-02,  3.8327e-02, -8.3676e-02, -3.3140e-02, -3.8570e-02,\n",
              "                      -4.2576e-02,  3.4867e-03,  4.1104e-02, -9.4159e-02])),\n",
              "             ('transformer.layers.3.self_attn.out_proj.weight',\n",
              "              tensor([[-0.0985,  0.0156,  0.0892,  ...,  0.0079, -0.0440, -0.0324],\n",
              "                      [-0.2091, -0.1184,  0.1665,  ...,  0.0369, -0.0639, -0.1424],\n",
              "                      [-0.0785,  0.0016, -0.0375,  ...,  0.0839,  0.0788, -0.0021],\n",
              "                      ...,\n",
              "                      [-0.0118,  0.1685,  0.0205,  ...,  0.0014,  0.0636, -0.1471],\n",
              "                      [ 0.0617, -0.1411,  0.0389,  ...,  0.0345, -0.0969, -0.0527],\n",
              "                      [-0.0068,  0.0414, -0.0374,  ...,  0.0314,  0.1420,  0.0592]])),\n",
              "             ('transformer.layers.3.self_attn.out_proj.bias',\n",
              "              tensor([-0.0365,  0.0032,  0.1409,  0.1624,  0.0257, -0.1524,  0.0052, -0.0450,\n",
              "                      -0.0280,  0.1490, -0.0139, -0.0780, -0.0655, -0.1815, -0.0894,  0.0346,\n",
              "                      -0.0645,  0.0994, -0.0673, -0.0257,  0.0917,  0.1523, -0.0602, -0.2385,\n",
              "                      -0.0586, -0.0326,  0.0152, -0.3021, -0.1596, -0.0191,  0.0043, -0.0090,\n",
              "                      -0.1380,  0.0347, -0.0303,  0.1646, -0.0771,  0.0921,  0.2621, -0.0034,\n",
              "                       0.1099, -0.1677,  0.0215,  0.0272, -0.0581, -0.0438,  0.1149,  0.2367,\n",
              "                      -0.1315, -0.0783, -0.0977, -0.0836,  0.1445, -0.0841, -0.1463,  0.1524,\n",
              "                       0.0997, -0.0434, -0.0126,  0.0039, -0.0741,  0.0104,  0.1296,  0.0885,\n",
              "                      -0.0799,  0.0747,  0.0640,  0.1106,  0.0421,  0.0938, -0.1590, -0.0583,\n",
              "                       0.0399,  0.1170,  0.1309,  0.0632, -0.1309,  0.0307,  0.0122,  0.0451,\n",
              "                       0.1276, -0.1144,  0.1591, -0.0895,  0.1045, -0.0948,  0.0424, -0.2270,\n",
              "                      -0.0223, -0.0686,  0.0244, -0.1437, -0.0926, -0.0067,  0.1736,  0.0419,\n",
              "                       0.2191, -0.1954, -0.1286,  0.0414, -0.0312, -0.0348,  0.0582,  0.0845,\n",
              "                       0.0045, -0.1091, -0.0604,  0.0122,  0.2016,  0.0484,  0.0990, -0.0049,\n",
              "                      -0.0470, -0.1128,  0.0761, -0.1145, -0.0766, -0.0069, -0.1032,  0.0590,\n",
              "                       0.0490, -0.0428, -0.1365,  0.0175,  0.1181, -0.0252, -0.0061,  0.1386])),\n",
              "             ('transformer.layers.3.linear1.weight',\n",
              "              tensor([[ 0.1554, -0.0304,  0.0020,  ...,  0.2256,  0.0064,  0.3022],\n",
              "                      [-0.1240, -0.0016,  0.2103,  ...,  0.2049, -0.0429,  0.0814],\n",
              "                      [-0.0680, -0.1418, -0.2551,  ...,  0.0080,  0.3028, -0.1403],\n",
              "                      ...,\n",
              "                      [ 0.1394,  0.0862,  0.0194,  ...,  0.0108,  0.0122,  0.2474],\n",
              "                      [-0.4225, -0.1173,  0.0960,  ...,  0.1300,  0.0279,  0.0123],\n",
              "                      [-0.0660, -0.0735, -0.0259,  ...,  0.2659, -0.5473, -0.0794]])),\n",
              "             ('transformer.layers.3.linear1.bias',\n",
              "              tensor([-0.1857, -0.0642, -0.3197, -0.2775, -0.2662, -0.3494, -0.2062, -0.1102,\n",
              "                      -0.0290, -0.0702, -0.0534, -0.2830, -0.1829, -0.1921, -0.0160, -0.2519,\n",
              "                      -0.2790, -0.3460, -0.2378, -0.3061, -0.3680, -0.2420,  0.0037, -0.1696,\n",
              "                      -0.3331, -0.4068, -0.3401,  0.1210, -0.1906, -0.0383, -0.2268, -0.2073,\n",
              "                      -0.1973, -0.1584, -0.2697, -0.1264, -0.0597, -0.3056, -0.0736, -0.1254,\n",
              "                      -0.2136, -0.2845, -0.0800, -0.1730, -0.2530, -0.1014,  0.0422, -0.1489,\n",
              "                      -0.2737, -0.2569, -0.2251, -0.2911, -0.2069, -0.1135, -0.2711, -0.0787,\n",
              "                      -0.1182, -0.2191, -0.2255, -0.2042, -0.0885, -0.2410, -0.1674, -0.3886,\n",
              "                      -0.2957, -0.1125, -0.3772, -0.3003, -0.1634, -0.0638, -0.2025,  0.0413,\n",
              "                      -0.3006, -0.1961, -0.3726, -0.2051, -0.4005, -0.1050, -0.1588, -0.2361,\n",
              "                      -0.2040, -0.3517, -0.0535, -0.1239, -0.1982, -0.1368, -0.2609, -0.2576,\n",
              "                      -0.1421, -0.0824, -0.1427, -0.3191, -0.0720, -0.1144, -0.1792, -0.3384,\n",
              "                      -0.3682, -0.0134, -0.2919, -0.1496, -0.4740, -0.3361, -0.2719, -0.2896,\n",
              "                      -0.0824, -0.3441, -0.1141, -0.2250,  0.0022, -0.1847, -0.4310, -0.2154,\n",
              "                      -0.1213, -0.1365, -0.3671, -0.4161, -0.1352, -0.0310, -0.1572, -0.2511,\n",
              "                      -0.1065, -0.2431, -0.2617,  0.1127, -0.1015, -0.0965, -0.2659, -0.1708,\n",
              "                      -0.2253, -0.3112, -0.0628, -0.3161, -0.2459, -0.4203, -0.2861, -0.2072,\n",
              "                      -0.2133, -0.2262, -0.2782, -0.3068, -0.2176, -0.2431, -0.4034, -0.2140,\n",
              "                      -0.2765,  0.0049, -0.1425, -0.1324, -0.2879, -0.0338, -0.1686, -0.1475,\n",
              "                      -0.0656, -0.1503, -0.0327, -0.1229, -0.2929, -0.2569, -0.3692, -0.3841,\n",
              "                      -0.1758, -0.4527, -0.1684, -0.2277, -0.1504, -0.2345, -0.2494, -0.0971,\n",
              "                      -0.0477, -0.1209, -0.1561, -0.4030, -0.3463, -0.2182, -0.3128, -0.3010,\n",
              "                      -0.2095, -0.1852, -0.0743,  0.0601, -0.4414, -0.3127, -0.2280, -0.3298,\n",
              "                      -0.0189,  0.0197, -0.0871,  0.0823, -0.1627, -0.1739, -0.2049, -0.1446,\n",
              "                      -0.1828, -0.3454, -0.2932, -0.1257, -0.1419, -0.3580,  0.0617, -0.4774,\n",
              "                      -0.4883, -0.1220, -0.2430, -0.3400, -0.0741, -0.2567, -0.1035, -0.0458,\n",
              "                      -0.2590, -0.4124, -0.1073, -0.4069, -0.3241, -0.0666, -0.2915, -0.3586,\n",
              "                       0.0968, -0.1286, -0.2509, -0.1594, -0.3321, -0.2631, -0.2002, -0.1014,\n",
              "                      -0.1225, -0.1041, -0.0739, -0.1353, -0.1327, -0.1590, -0.1773, -0.1741,\n",
              "                      -0.2366, -0.2396, -0.2934, -0.1597, -0.1757, -0.2763, -0.2284, -0.1950,\n",
              "                      -0.4032, -0.3065, -0.2591, -0.1852, -0.1594, -0.1337, -0.3917, -0.3707,\n",
              "                      -0.3058, -0.1755, -0.1144, -0.2260, -0.1307, -0.0900, -0.3051, -0.2591])),\n",
              "             ('transformer.layers.3.linear2.weight',\n",
              "              tensor([[ 0.2013, -0.2874,  0.1281,  ...,  0.0923,  0.2135,  0.5013],\n",
              "                      [ 0.1160,  0.2205,  0.0422,  ...,  0.0489,  0.1295,  0.2910],\n",
              "                      [ 0.0352,  0.0045,  0.0010,  ...,  0.0834,  0.1475,  0.0640],\n",
              "                      ...,\n",
              "                      [-0.5779,  0.1157, -0.0261,  ..., -0.3041, -0.1161, -0.6270],\n",
              "                      [-0.0729, -0.1080, -0.0651,  ..., -0.0845, -0.1199, -0.1487],\n",
              "                      [ 0.0785,  0.2156,  0.2170,  ...,  0.0526,  0.1294,  0.2321]])),\n",
              "             ('transformer.layers.3.linear2.bias',\n",
              "              tensor([ 6.4283e-01,  3.8970e-02, -1.0249e-01,  1.6851e+00, -4.7656e-02,\n",
              "                      -1.5775e+00,  9.6559e-02,  3.3490e-03, -1.1870e+00,  7.6751e-04,\n",
              "                      -2.4256e-02,  3.6110e-03, -2.8757e-03, -1.5570e+00,  2.4526e-02,\n",
              "                      -1.9040e-02, -1.7140e-02,  1.1270e+00,  1.0280e-02, -6.5785e-02,\n",
              "                       1.6458e+00, -1.2322e-01, -8.0948e-01, -1.5184e+00,  4.8549e-02,\n",
              "                      -1.3359e+00,  2.6354e-02, -1.6763e+00, -4.6465e-02,  1.8385e-02,\n",
              "                       7.0066e-02, -4.5125e-02,  2.9975e-02, -5.6664e-02,  1.5180e+00,\n",
              "                       1.1350e-01,  3.5285e-02,  5.7896e-02,  6.0760e-01, -3.0331e-02,\n",
              "                       3.1279e-02, -1.5428e+00,  2.0603e-02, -4.0728e-02, -3.3408e-02,\n",
              "                      -7.7163e-02, -5.5288e-02,  1.5665e+00, -6.9177e-02,  8.0568e-02,\n",
              "                      -1.5960e+00,  1.4545e+00, -6.3105e-02, -1.5621e+00,  4.1419e-02,\n",
              "                       1.6535e+00,  4.6667e-02,  3.2566e-01,  4.9427e-02,  1.5302e-02,\n",
              "                      -1.4469e+00,  1.6259e+00, -1.6047e-02,  9.2167e-02, -4.9475e-02,\n",
              "                       1.4804e-02,  7.6241e-02,  1.5076e+00,  2.4357e-02,  8.3390e-02,\n",
              "                      -3.2587e-02,  2.2583e-02,  3.1203e-03,  1.6591e+00, -3.4408e-02,\n",
              "                       1.8687e-02, -3.4749e-02, -1.3529e-01,  3.3137e-02,  6.3389e-01,\n",
              "                       2.1596e-02, -1.3273e+00,  1.6156e+00,  5.6581e-03,  1.2520e-01,\n",
              "                       4.2610e-02, -6.1262e-02, -2.2245e-01,  1.5942e+00, -1.6253e+00,\n",
              "                      -4.1048e-02, -1.6992e+00, -1.4433e+00, -3.5561e-02, -2.1364e-02,\n",
              "                       3.6372e-02,  1.5582e+00, -1.6527e+00, -2.8049e-02, -3.3380e-02,\n",
              "                       1.1885e+00,  1.4321e+00,  5.8394e-02, -1.5212e-02, -8.2132e-02,\n",
              "                       1.8890e-02,  4.6445e-02,  1.7239e-02,  2.9431e-01, -3.0115e-01,\n",
              "                       1.6124e+00,  4.7180e-02,  8.5322e-02, -1.6609e-01, -6.8014e-02,\n",
              "                      -1.6586e+00, -1.5763e+00,  6.3724e-02,  7.7799e-02,  4.6858e-02,\n",
              "                       7.1524e-01, -1.8168e-02, -3.5816e-03,  1.5751e+00, -4.7868e-02,\n",
              "                      -1.5737e+00,  5.7569e-03, -9.6992e-02])),\n",
              "             ('transformer.layers.3.norm1.weight',\n",
              "              tensor([0.3441, 0.3606, 0.8138, 0.7558, 0.8606, 0.7594, 0.6189, 0.7545, 0.7395,\n",
              "                      0.8848, 1.0142, 0.7011, 0.1685, 0.1915, 0.8248, 1.0301, 1.0483, 0.7003,\n",
              "                      0.7120, 0.3013, 0.2928, 0.2873, 0.8585, 0.7188, 1.0211, 0.9348, 0.8545,\n",
              "                      0.9972, 1.0971, 0.7605, 0.4642, 0.6524, 0.8938, 0.9045, 0.8131, 0.6534,\n",
              "                      0.8492, 0.5669, 0.7574, 1.0199, 0.7978, 0.9915, 0.9354, 0.8841, 0.7467,\n",
              "                      0.9742, 1.2363, 0.7812, 0.6119, 1.1771, 1.2162, 0.9515, 0.7543, 1.1569,\n",
              "                      1.0934, 1.2090, 1.1433, 0.9396, 1.0930, 1.1462, 1.1025, 1.1121, 1.1094,\n",
              "                      0.8785, 1.0058, 1.1770, 1.2282, 1.0998, 0.9670, 0.8770, 1.0033, 1.1069,\n",
              "                      1.0655, 0.8960, 0.9917, 1.2150, 0.6835, 1.3038, 1.1512, 0.8877, 0.8620,\n",
              "                      0.8450, 1.1961, 1.1072, 1.0426, 1.2591, 1.0736, 0.8243, 1.1629, 1.4509,\n",
              "                      0.9718, 1.1609, 0.9676, 0.5518, 0.8976, 0.8667, 0.5816, 0.9023, 1.1750,\n",
              "                      0.7243, 0.7963, 0.7702, 0.9419, 1.1889, 1.0385, 0.9095, 1.0098, 0.9781,\n",
              "                      0.9621, 1.0033, 1.0201, 1.0026, 1.1904, 0.6932, 1.0024, 1.0854, 1.1961,\n",
              "                      1.0252, 0.8792, 0.9667, 0.9819, 0.7825, 0.9902, 1.0913, 1.0153, 1.0039,\n",
              "                      1.1348, 1.1227])),\n",
              "             ('transformer.layers.3.norm1.bias',\n",
              "              tensor([ 3.5986e-01,  2.9156e-01,  2.7935e-01,  5.3928e-01,  6.6884e-02,\n",
              "                      -5.6845e-01, -3.7123e-02, -3.0396e-02, -2.6553e-02,  1.1981e-01,\n",
              "                       5.1809e-03,  2.0918e-01, -9.9268e-02, -6.6871e-01,  1.6897e-01,\n",
              "                      -2.1910e-02, -7.2020e-02,  1.7059e-01, -1.8979e-01, -2.7740e-01,\n",
              "                       5.8132e-01, -1.8607e-02, -4.8913e-01, -8.4492e-01,  5.2350e-02,\n",
              "                      -3.0629e-01,  1.2495e-01, -1.1319e+00, -1.8623e-02,  2.9294e-02,\n",
              "                      -1.2987e-01,  2.1250e-02, -4.0906e-02,  1.5200e-01,  1.8676e-01,\n",
              "                       5.5263e-01, -2.1145e-01, -1.0733e-01,  4.9971e-01, -1.7558e-01,\n",
              "                       9.6859e-02, -7.1980e-01, -3.8227e-02, -5.2453e-02, -5.7958e-02,\n",
              "                       9.2282e-02,  1.0234e-01,  5.8703e-01,  2.8554e-01, -1.4421e-01,\n",
              "                      -4.4708e-01, -1.2485e-01,  2.9488e-01, -2.2317e-01,  1.0075e-01,\n",
              "                       1.2542e+00, -4.1357e-02, -1.6205e-01, -1.9028e-01,  1.6102e-01,\n",
              "                      -2.2566e-01,  4.7981e-01,  1.6897e-01, -9.3823e-05, -9.7772e-02,\n",
              "                       4.6914e-01,  1.5680e-01,  3.8344e-01, -4.3873e-02,  9.6327e-02,\n",
              "                      -6.3558e-02,  9.4302e-02, -2.2574e-01,  5.1729e-01,  1.0143e-01,\n",
              "                       1.6837e-01, -2.3524e-03,  2.4233e-01, -1.2476e-01, -1.9160e-01,\n",
              "                       2.9769e-01, -4.2330e-01,  8.0216e-01, -1.3714e-01,  7.2702e-02,\n",
              "                      -1.2690e-01, -1.7666e-01, -8.3404e-01,  3.1662e-01, -6.1775e-01,\n",
              "                      -2.3738e-01, -6.1874e-01, -1.8751e-01,  2.3346e-01,  6.3112e-02,\n",
              "                      -1.6940e-01,  2.1115e-01, -8.2549e-01, -1.1015e-01,  1.4632e-01,\n",
              "                      -2.9071e-01,  2.8706e-01,  8.1619e-02,  1.0547e-01, -2.2653e-01,\n",
              "                      -7.0140e-02,  2.0635e-01, -1.2482e-01,  2.4654e-01, -7.6079e-02,\n",
              "                       2.6132e-01, -1.9518e-02,  2.7843e-01, -3.9201e-01,  1.6072e-01,\n",
              "                      -5.4509e-01, -3.2017e-01, -4.8734e-02, -1.4745e-01,  5.7307e-02,\n",
              "                       2.3832e-01, -1.9474e-01, -7.5931e-02,  2.1943e-01,  6.1838e-02,\n",
              "                      -3.5657e-01,  1.0467e-02,  2.1675e-01])),\n",
              "             ('transformer.layers.3.norm2.weight',\n",
              "              tensor([ 2.9154e-01,  8.4514e-01,  8.1862e-01,  2.4086e-01,  8.9416e-01,\n",
              "                       2.5623e-01,  7.9491e-01,  9.1034e-01, -4.4938e-03,  9.0668e-01,\n",
              "                       8.6161e-01,  7.2012e-01,  7.9847e-01,  2.0740e-01,  7.0863e-01,\n",
              "                       8.5592e-01,  8.9989e-01,  2.7242e-01,  8.5423e-01,  5.3063e-01,\n",
              "                       2.5100e-01,  7.2403e-01,  3.7402e-01,  1.9905e-01,  8.5868e-01,\n",
              "                       1.7412e-01,  8.8240e-01,  2.3636e-01,  8.4179e-01,  8.0101e-01,\n",
              "                       6.7960e-01,  8.1579e-01,  8.8576e-01,  9.0591e-01,  2.3829e-01,\n",
              "                       7.3407e-01,  8.5775e-01,  7.7500e-01,  1.3377e-01,  7.9996e-01,\n",
              "                       8.2027e-01,  2.1296e-01,  8.5513e-01,  8.0101e-01,  7.9616e-01,\n",
              "                       8.4256e-01,  9.1004e-01,  1.8845e-01,  8.0427e-01,  8.9101e-01,\n",
              "                       2.4325e-01,  1.0466e-01,  6.4515e-01,  2.0950e-01,  8.5557e-01,\n",
              "                       2.0248e-01,  9.0811e-01,  2.3339e-06,  8.2253e-01,  8.6901e-01,\n",
              "                       1.6837e-01,  2.3019e-01,  8.2546e-01,  6.4188e-01,  8.0357e-01,\n",
              "                       7.5526e-01,  7.4085e-01,  2.6700e-01,  8.4112e-01,  7.7853e-01,\n",
              "                       7.8832e-01,  7.9473e-01,  2.9813e-01,  2.3081e-01,  8.6020e-01,\n",
              "                       8.1852e-01,  7.4917e-01,  9.3979e-01,  9.2599e-01,  1.8260e-01,\n",
              "                       8.2509e-01,  1.8498e-01,  2.2582e-01,  8.0024e-01,  7.8074e-01,\n",
              "                       8.7352e-01,  7.1924e-01,  6.9275e-01,  2.2725e-01,  2.2052e-01,\n",
              "                       8.5111e-01,  2.2008e-01,  1.9062e-01,  7.6269e-01,  5.6034e-01,\n",
              "                       8.5606e-01,  2.1988e-01,  2.1127e-01,  8.6507e-01,  7.7192e-01,\n",
              "                       2.2263e-01,  2.4726e-01,  7.9612e-01,  9.0395e-01,  7.7205e-01,\n",
              "                       8.2538e-01,  8.3050e-01,  8.5441e-01,  2.7319e-04,  1.5778e-01,\n",
              "                       1.5251e-01,  7.8720e-01,  7.7281e-01,  5.4768e-01,  7.6035e-01,\n",
              "                       1.9760e-01,  2.0279e-01,  9.1338e-01,  8.7759e-01,  8.5376e-01,\n",
              "                       1.0585e-04,  7.8267e-01,  8.5014e-01,  2.5330e-01,  8.0458e-01,\n",
              "                       1.8193e-01,  8.8856e-01,  9.0315e-01])),\n",
              "             ('transformer.layers.3.norm2.bias',\n",
              "              tensor([-2.4698e-01, -2.9750e-02,  1.3736e-02, -4.3758e-01,  2.5656e-02,\n",
              "                       4.1443e-01, -2.7338e-02,  2.9056e-02, -4.8906e-03, -5.1235e-03,\n",
              "                      -5.7663e-02, -6.9827e-03, -1.9688e-02,  4.6081e-01, -5.5841e-02,\n",
              "                       5.3514e-02, -2.5114e-02, -3.4734e-01,  6.3061e-02, -1.0170e-02,\n",
              "                      -4.6718e-01,  7.1662e-02,  2.4130e-01,  4.4434e-01, -2.8146e-02,\n",
              "                       2.9389e-01, -4.3997e-02,  4.6948e-01, -4.3197e-02, -4.1167e-02,\n",
              "                      -4.9717e-02, -6.2654e-02, -3.7851e-02,  4.3787e-02, -4.1769e-01,\n",
              "                      -9.5282e-02, -2.9249e-02,  9.0862e-03, -1.0551e-01,  1.2198e-01,\n",
              "                       2.9490e-02,  4.5505e-01, -9.9209e-03,  4.4692e-02, -3.9332e-02,\n",
              "                       3.5650e-02,  2.5656e-02, -3.0552e-01,  1.8418e-02,  1.3028e-02,\n",
              "                       4.8917e-01, -2.0874e-01,  4.7299e-02,  3.7579e-01, -1.0612e-01,\n",
              "                      -4.7456e-01,  8.1377e-03, -3.9611e-06, -1.4043e-02,  5.3267e-02,\n",
              "                       2.9336e-01, -4.5842e-01, -7.6339e-02, -7.6814e-03,  6.1428e-02,\n",
              "                      -8.8085e-02,  3.1304e-02, -4.3637e-01,  3.2372e-02, -4.6392e-02,\n",
              "                      -1.7035e-02, -5.0880e-02,  7.6247e-02, -4.5497e-01,  1.9510e-02,\n",
              "                      -1.0094e-01, -3.4786e-02,  3.0414e-02,  5.4700e-02, -1.8279e-01,\n",
              "                      -3.0447e-03,  3.1060e-01, -4.5608e-01,  6.0196e-02, -1.3135e-02,\n",
              "                      -2.6080e-02,  9.5448e-02,  1.8584e-01, -4.2863e-01,  4.4689e-01,\n",
              "                      -6.4007e-03,  4.0832e-01,  3.2720e-01,  1.9209e-02,  2.0242e-03,\n",
              "                      -1.1511e-02, -4.1625e-01,  4.4616e-01, -4.3305e-02,  1.1866e-02,\n",
              "                      -2.5303e-01, -3.7003e-01,  1.5186e-02,  2.0563e-03,  1.5254e-02,\n",
              "                       4.5961e-02,  2.6194e-02,  7.6175e-02, -5.7345e-04, -9.0851e-03,\n",
              "                      -3.2266e-01, -1.1321e-02, -1.1355e-01,  1.2472e-01, -6.5956e-03,\n",
              "                       3.8564e-01,  3.9979e-01, -3.5273e-02,  3.8169e-02, -4.3795e-03,\n",
              "                      -6.4375e-05, -3.3003e-02,  2.4407e-02, -4.0992e-01, -6.8241e-04,\n",
              "                       3.3915e-01, -5.3685e-02, -1.4583e-02])),\n",
              "             ('fc.weight',\n",
              "              tensor([[ 3.6129e-02,  2.9141e-02,  5.7515e-02, -3.5802e-02,  8.4167e-02,\n",
              "                        2.8842e-02, -7.7867e-02,  4.7438e-02, -3.1076e-02,  7.4672e-02,\n",
              "                       -6.5136e-02,  3.3373e-02, -7.5946e-02, -6.6010e-02, -2.7618e-02,\n",
              "                        5.5228e-02, -6.8921e-02, -2.1947e-02,  1.2751e-01,  1.5342e-03,\n",
              "                        2.1283e-03,  8.5161e-02, -2.2685e-02, -2.8720e-02, -7.8662e-02,\n",
              "                       -3.4088e-02, -7.8693e-02, -5.0498e-02, -1.3950e-02, -6.4156e-02,\n",
              "                       -2.6158e-02, -5.5354e-02, -1.0378e-01,  1.0806e-01,  4.9547e-02,\n",
              "                        4.7836e-02, -7.5835e-02, -2.7899e-02, -1.1293e-04,  2.2638e-03,\n",
              "                        5.0842e-02,  9.1946e-03, -6.1292e-02,  7.3604e-02, -6.8624e-02,\n",
              "                        7.3093e-02,  4.1131e-02, -6.0634e-02,  4.9489e-02, -4.0391e-02,\n",
              "                       -3.5458e-02, -5.8973e-02,  5.6213e-02,  5.8207e-02, -1.8589e-02,\n",
              "                        7.6373e-02, -7.9314e-02,  3.5220e-04, -3.8611e-02,  6.7317e-02,\n",
              "                       -7.8006e-02, -8.2901e-03, -6.4273e-02,  4.0668e-02,  1.9898e-02,\n",
              "                       -1.0830e-02,  7.5567e-02,  1.7059e-02,  4.5826e-02, -1.2052e-01,\n",
              "                       -9.1504e-02, -9.1943e-02,  1.1553e-02,  3.5159e-02,  4.0375e-02,\n",
              "                       -1.0189e-01, -3.4785e-02,  1.2928e-01,  6.0916e-02,  5.8443e-02,\n",
              "                        2.1080e-02,  1.0919e-02,  4.6346e-02, -9.3693e-03,  4.1035e-02,\n",
              "                       -8.1467e-02,  7.6404e-02, -3.5754e-02,  6.3820e-02,  2.7836e-02,\n",
              "                       -6.8964e-02, -6.1132e-02, -7.4344e-02,  3.0083e-02,  6.7987e-02,\n",
              "                       -2.6150e-02,  4.3004e-02, -1.5443e-02, -3.6019e-02,  2.6111e-02,\n",
              "                       -8.2757e-03, -5.2860e-02, -1.0522e-01,  1.1000e-01, -6.2382e-02,\n",
              "                        2.5630e-02,  2.3944e-02,  7.8173e-02,  6.6183e-02,  5.6486e-02,\n",
              "                        3.0436e-02, -1.1029e-01, -2.8506e-02,  1.1856e-01,  5.5222e-02,\n",
              "                        5.9925e-02,  4.0623e-03, -5.7889e-02, -7.1495e-02,  4.4620e-02,\n",
              "                        6.0802e-02, -4.2926e-02,  9.3015e-02,  1.0218e-02,  5.4509e-02,\n",
              "                        2.4588e-02, -5.4508e-02,  8.5529e-02],\n",
              "                      [ 4.6627e-02, -1.1493e-01, -6.5709e-02, -5.4529e-02, -7.0538e-02,\n",
              "                        5.9006e-02,  1.0774e-01, -1.1108e-01, -2.6868e-02, -1.0516e-01,\n",
              "                        1.0043e-01, -1.0813e-01,  7.1792e-02, -8.6019e-02,  9.5444e-02,\n",
              "                       -1.0410e-01,  1.2669e-01, -2.2836e-02, -6.0907e-02,  1.0160e-01,\n",
              "                        1.6882e-02, -6.2964e-02, -2.7579e-03, -3.3369e-02,  6.5587e-02,\n",
              "                       -4.2302e-02,  7.8555e-02, -5.6475e-02,  1.1507e-01,  1.0339e-01,\n",
              "                        1.1226e-01,  9.7418e-02,  8.1335e-02, -5.4969e-02,  3.3782e-02,\n",
              "                       -1.1262e-01,  8.3841e-02,  1.1847e-01,  1.4620e-02, -1.3896e-01,\n",
              "                       -9.0301e-02, -1.4266e-02,  1.0310e-01, -8.7326e-02,  8.1318e-02,\n",
              "                       -9.3350e-02, -1.2550e-01, -6.1964e-02, -7.5085e-02,  1.2634e-01,\n",
              "                       -9.0459e-02, -4.2573e-02, -5.2834e-02,  7.0354e-03,  1.1955e-01,\n",
              "                        7.0057e-02,  8.6958e-02,  3.5392e-04,  9.8073e-02, -9.9394e-02,\n",
              "                       -6.1226e-02,  3.8485e-02,  1.0611e-01, -8.2296e-02, -1.3107e-01,\n",
              "                        1.6673e-01, -8.5381e-02, -2.4302e-03, -1.0408e-01,  2.8697e-02,\n",
              "                        2.8856e-02,  6.0837e-02, -1.8997e-02,  6.2150e-02, -7.5689e-02,\n",
              "                        5.5566e-02,  7.5104e-02, -6.2142e-02, -1.3379e-01,  8.2422e-02,\n",
              "                       -1.0931e-01, -5.3598e-03,  3.6765e-02,  1.3408e-01, -1.3838e-01,\n",
              "                        9.2690e-02, -9.8142e-02,  7.9508e-02,  1.5051e-02, -9.1027e-03,\n",
              "                        8.8535e-02, -5.8424e-02, -6.0886e-02, -8.4334e-02, -8.0157e-02,\n",
              "                        1.4172e-01,  5.7880e-02, -3.0076e-02,  1.3283e-01, -8.4344e-02,\n",
              "                       -1.7081e-02, -6.7148e-02,  7.4700e-02, -6.1963e-02,  6.1849e-02,\n",
              "                       -1.4827e-01, -1.4144e-01, -1.0325e-01,  6.6098e-02,  2.9478e-02,\n",
              "                        2.9830e-02,  6.8867e-02,  1.2947e-01, -7.8311e-02, -1.0349e-01,\n",
              "                        6.1044e-02,  1.6089e-02,  1.4619e-01,  1.0344e-01, -9.8363e-02,\n",
              "                        6.0981e-02,  1.2350e-01, -8.3759e-02, -1.0722e-02, -7.2889e-02,\n",
              "                        2.2753e-02,  1.1813e-01, -7.7575e-02]])),\n",
              "             ('fc.bias', tensor([ 0.4449, -0.3543])),\n",
              "             ('crf.transitions',\n",
              "              tensor([[-0.4422,  0.1126],\n",
              "                      [-0.0900, -0.8078]])),\n",
              "             ('crf.start_transitions', tensor([0.1505, 0.0616])),\n",
              "             ('crf.end_transitions', tensor([ 0.3556, -2.2656]))])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обрабатываем тестовые данные"
      ],
      "metadata": {
        "id": "pVNKf4U6aEuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "task_data = {'id': [], 'predicted_positions': []}\n",
        "\n",
        "for i in tqdm(range(len(data)), desc=\"Обработка тестовых данных\"):\n",
        "    original = data['text_no_spaces'][i]\n",
        "    if not isinstance(original, str) or len(original) == 0:\n",
        "        task_data['id'].append(i)\n",
        "        task_data['predicted_positions'].append([])\n",
        "        continue\n",
        "\n",
        "    ids = [char2id.get(c, char2id[\"<UNK>\"]) for c in original[:128]]\n",
        "    if len(ids) < 128:\n",
        "        ids += [char2id[\"<PAD>\"]] * (128 - len(ids))\n",
        "    x = torch.tensor(ids, dtype=torch.long).unsqueeze(0).to(device)\n",
        "    mask = torch.tensor([1 if i < len(original) else 0 for i in range(128)], dtype=torch.bool).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred_tags = model(x, mask=mask)\n",
        "        positions = [idx + 1 for idx, tag in enumerate(pred_tags[0][:len(original)]) if tag == 1]\n",
        "\n",
        "    task_data['id'].append(i)\n",
        "    task_data['predicted_positions'].append(positions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STQ-k76E0wlY",
        "outputId": "6363c113-e6dc-4886-82eb-a59e4ff7f66e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обработка тестовых данных: 100%|██████████| 1005/1005 [00:16<00:00, 59.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Проверяем, как модель расставляет пробелы"
      ],
      "metadata": {
        "id": "Tta-9XX4aHNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame(task_data)\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"\\n✅ Результаты сохранены в submission.csv\")\n",
        "\n",
        "print(\"\\nПримеры результатов:\")\n",
        "for i in range(min(14, len(data))):\n",
        "    original = data['text_no_spaces'][i]\n",
        "    if not isinstance(original, str):\n",
        "        continue\n",
        "    positions = task_data['predicted_positions'][i]\n",
        "    segmented = restore_spaces(original, positions)\n",
        "    print(f\"[{i}] Оригинал: {original}\")\n",
        "    print(f\"        Восстановлено: {segmented}\")\n",
        "    print(f\"        Позиции: {positions}\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI_6IDQl01qo",
        "outputId": "0096a5e5-5840-44d6-e884-912a2ab8d0a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Результаты сохранены в submission.csv\n",
            "\n",
            "Примеры результатов:\n",
            "[0] Оригинал: куплюайфон14про\n",
            "        Восстановлено: куплю айфон 14 про\n",
            "        Позиции: [5, 10, 12, 15]\n",
            "--------------------------------------------------\n",
            "[1] Оригинал: ищудомвПодмосковье\n",
            "        Восстановлено: и щудом в Подмосковье\n",
            "        Позиции: [1, 6, 7]\n",
            "--------------------------------------------------\n",
            "[2] Оригинал: сдаюквартирусмебельюитехникой\n",
            "        Восстановлено: с даю квартиру с мебелью и техникой\n",
            "        Позиции: [1, 4, 12, 13, 20, 21]\n",
            "--------------------------------------------------\n",
            "[3] Оригинал: новыйдивандоставканедорого\n",
            "        Восстановлено: новый диван доставка недорого\n",
            "        Позиции: [5, 10, 18]\n",
            "--------------------------------------------------\n",
            "[4] Оригинал: отдамдаромкошку\n",
            "        Восстановлено: отдам даром кошку\n",
            "        Позиции: [5, 10]\n",
            "--------------------------------------------------\n",
            "[5] Оригинал: работавМосквеудаленно\n",
            "        Восстановлено: работа в Москве удаленно\n",
            "        Позиции: [6, 7, 13]\n",
            "--------------------------------------------------\n",
            "[6] Оригинал: куплютелевизорPhilips\n",
            "        Восстановлено: куплю телевизор Philips\n",
            "        Позиции: [5, 14]\n",
            "--------------------------------------------------\n",
            "[7] Оригинал: ищугрузчиковдляпереезда\n",
            "        Восстановлено: ищу грузчиков для переезда\n",
            "        Позиции: [3, 12, 15]\n",
            "--------------------------------------------------\n",
            "[8] Оригинал: ремонтквартирподключ\n",
            "        Восстановлено: ремонт квартир под ключ\n",
            "        Позиции: [6, 13, 16]\n",
            "--------------------------------------------------\n",
            "[9] Оригинал: куплюноутбукHP\n",
            "        Восстановлено: куплюноутбук HP\n",
            "        Позиции: [12]\n",
            "--------------------------------------------------\n",
            "[10] Оригинал: ищуквартирууметро\n",
            "        Восстановлено: ищу квартиру уметро\n",
            "        Позиции: [3, 11]\n",
            "--------------------------------------------------\n",
            "[11] Оригинал: новаямикроволновкаSamsung\n",
            "        Восстановлено: новая микроволновка Samsung\n",
            "        Позиции: [5, 18]\n",
            "--------------------------------------------------\n",
            "[12] Оригинал: срочнопродамвелосипед\n",
            "        Восстановлено: срочно продам велосипед\n",
            "        Позиции: [6, 12]\n",
            "--------------------------------------------------\n",
            "[13] Оригинал: куплюгитаруFender\n",
            "        Восстановлено: ку плюгитару Fender\n",
            "        Позиции: [2, 11]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}